[2023-05-29T10:31:09.243+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: stock_market_dag.feature_engineering_stocks manual__2023-05-29T09:26:54.433175+00:00 [queued]>
[2023-05-29T10:31:09.252+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: stock_market_dag.feature_engineering_stocks manual__2023-05-29T09:26:54.433175+00:00 [queued]>
[2023-05-29T10:31:09.252+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-05-29T10:31:09.303+0000] {taskinstance.py:1327} INFO - Executing <Task(BashOperator): feature_engineering_stocks> on 2023-05-29 09:26:54.433175+00:00
[2023-05-29T10:31:09.306+0000] {standard_task_runner.py:57} INFO - Started process 45070 to run task
[2023-05-29T10:31:09.310+0000] {standard_task_runner.py:84} INFO - Running: ['airflow', 'tasks', 'run', 'stock_market_dag', 'feature_engineering_stocks', 'manual__2023-05-29T09:26:54.433175+00:00', '--job-id', '14', '--raw', '--subdir', 'DAGS_FOLDER/dag.py', '--cfg-path', '/tmp/tmpov9dtn3z']
[2023-05-29T10:31:09.312+0000] {standard_task_runner.py:85} INFO - Job 14: Subtask feature_engineering_stocks
[2023-05-29T10:31:09.385+0000] {task_command.py:410} INFO - Running <TaskInstance: stock_market_dag.feature_engineering_stocks manual__2023-05-29T09:26:54.433175+00:00 [running]> on host 4b5d28de6f1c.mylabserver.com
[2023-05-29T10:31:09.477+0000] {taskinstance.py:1545} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='stock_market_dag' AIRFLOW_CTX_TASK_ID='feature_engineering_stocks' AIRFLOW_CTX_EXECUTION_DATE='2023-05-29T09:26:54.433175+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-05-29T09:26:54.433175+00:00'
[2023-05-29T10:31:09.478+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2023-05-29T10:31:09.479+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'spark-submit /home/cloud_user/Stock-Market-Nasdaq/src/feature_engineering.py /home/cloud_user/Stock-Market-Nasdaq/data/processed_data/parquet_format stocks /home/cloud_user/Stock-Market-Nasdaq/data/processed_data/parquet_format_avg_med || true']
[2023-05-29T10:31:09.487+0000] {subprocess.py:86} INFO - Output:
[2023-05-29T10:31:22.734+0000] {subprocess.py:93} INFO - 23/05/29 10:31:22 INFO SparkContext: Running Spark version 3.4.0
[2023-05-29T10:31:23.211+0000] {subprocess.py:93} INFO - 23/05/29 10:31:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2023-05-29T10:31:23.947+0000] {subprocess.py:93} INFO - 23/05/29 10:31:23 INFO ResourceUtils: ==============================================================
[2023-05-29T10:31:23.948+0000] {subprocess.py:93} INFO - 23/05/29 10:31:23 INFO ResourceUtils: No custom resources configured for spark.driver.
[2023-05-29T10:31:23.950+0000] {subprocess.py:93} INFO - 23/05/29 10:31:23 INFO ResourceUtils: ==============================================================
[2023-05-29T10:31:23.951+0000] {subprocess.py:93} INFO - 23/05/29 10:31:23 INFO SparkContext: Submitted application: FeatureEngineering
[2023-05-29T10:31:24.179+0000] {subprocess.py:93} INFO - 23/05/29 10:31:24 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 8192, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2023-05-29T10:31:24.261+0000] {subprocess.py:93} INFO - 23/05/29 10:31:24 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor
[2023-05-29T10:31:24.268+0000] {subprocess.py:93} INFO - 23/05/29 10:31:24 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2023-05-29T10:31:24.661+0000] {subprocess.py:93} INFO - 23/05/29 10:31:24 INFO SecurityManager: Changing view acls to: cloud_user
[2023-05-29T10:31:24.665+0000] {subprocess.py:93} INFO - 23/05/29 10:31:24 INFO SecurityManager: Changing modify acls to: cloud_user
[2023-05-29T10:31:24.666+0000] {subprocess.py:93} INFO - 23/05/29 10:31:24 INFO SecurityManager: Changing view acls groups to:
[2023-05-29T10:31:24.668+0000] {subprocess.py:93} INFO - 23/05/29 10:31:24 INFO SecurityManager: Changing modify acls groups to:
[2023-05-29T10:31:24.669+0000] {subprocess.py:93} INFO - 23/05/29 10:31:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: cloud_user; groups with view permissions: EMPTY; users with modify permissions: cloud_user; groups with modify permissions: EMPTY
[2023-05-29T10:31:26.254+0000] {subprocess.py:93} INFO - 23/05/29 10:31:26 INFO Utils: Successfully started service 'sparkDriver' on port 44571.
[2023-05-29T10:31:26.409+0000] {subprocess.py:93} INFO - 23/05/29 10:31:26 INFO SparkEnv: Registering MapOutputTracker
[2023-05-29T10:31:26.510+0000] {subprocess.py:93} INFO - 23/05/29 10:31:26 INFO SparkEnv: Registering BlockManagerMaster
[2023-05-29T10:31:26.657+0000] {subprocess.py:93} INFO - 23/05/29 10:31:26 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2023-05-29T10:31:26.657+0000] {subprocess.py:93} INFO - 23/05/29 10:31:26 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2023-05-29T10:31:26.661+0000] {subprocess.py:93} INFO - 23/05/29 10:31:26 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2023-05-29T10:31:26.749+0000] {subprocess.py:93} INFO - 23/05/29 10:31:26 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-fd650928-841a-4851-8b2c-346ceeee5b90
[2023-05-29T10:31:26.902+0000] {subprocess.py:93} INFO - 23/05/29 10:31:26 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2023-05-29T10:31:26.987+0000] {subprocess.py:93} INFO - 23/05/29 10:31:26 INFO SparkEnv: Registering OutputCommitCoordinator
[2023-05-29T10:31:27.797+0000] {subprocess.py:93} INFO - 23/05/29 10:31:27 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2023-05-29T10:31:28.093+0000] {subprocess.py:93} INFO - 23/05/29 10:31:28 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2023-05-29T10:31:29.065+0000] {subprocess.py:93} INFO - 23/05/29 10:31:29 INFO Executor: Starting executor ID driver on host 4b5d28de6f1c.mylabserver.com
[2023-05-29T10:31:29.135+0000] {subprocess.py:93} INFO - 23/05/29 10:31:29 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2023-05-29T10:31:29.233+0000] {subprocess.py:93} INFO - 23/05/29 10:31:29 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39921.
[2023-05-29T10:31:29.234+0000] {subprocess.py:93} INFO - 23/05/29 10:31:29 INFO NettyBlockTransferService: Server created on 4b5d28de6f1c.mylabserver.com:39921
[2023-05-29T10:31:29.237+0000] {subprocess.py:93} INFO - 23/05/29 10:31:29 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2023-05-29T10:31:29.305+0000] {subprocess.py:93} INFO - 23/05/29 10:31:29 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 4b5d28de6f1c.mylabserver.com, 39921, None)
[2023-05-29T10:31:29.305+0000] {subprocess.py:93} INFO - 23/05/29 10:31:29 INFO BlockManagerMasterEndpoint: Registering block manager 4b5d28de6f1c.mylabserver.com:39921 with 434.4 MiB RAM, BlockManagerId(driver, 4b5d28de6f1c.mylabserver.com, 39921, None)
[2023-05-29T10:31:29.369+0000] {subprocess.py:93} INFO - 23/05/29 10:31:29 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 4b5d28de6f1c.mylabserver.com, 39921, None)
[2023-05-29T10:31:29.369+0000] {subprocess.py:93} INFO - 23/05/29 10:31:29 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 4b5d28de6f1c.mylabserver.com, 39921, None)
[2023-05-29T10:31:32.018+0000] {subprocess.py:93} INFO - 23/05/29 10:31:32 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2023-05-29T10:31:32.090+0000] {subprocess.py:93} INFO - 23/05/29 10:31:32 INFO SharedState: Warehouse path is 'file:/tmp/airflowtmpql4u13kf/spark-warehouse'.
[2023-05-29T10:31:37.055+0000] {subprocess.py:93} INFO - 23/05/29 10:31:37 INFO InMemoryFileIndex: It took 482 ms to list leaf files for 1 paths.
[2023-05-29T10:31:39.783+0000] {subprocess.py:93} INFO - 23/05/29 10:31:39 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
[2023-05-29T10:31:39.871+0000] {subprocess.py:93} INFO - 23/05/29 10:31:39 INFO DAGScheduler: Got job 0 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2023-05-29T10:31:39.871+0000] {subprocess.py:93} INFO - 23/05/29 10:31:39 INFO DAGScheduler: Final stage: ResultStage 0 (parquet at NativeMethodAccessorImpl.java:0)
[2023-05-29T10:31:39.873+0000] {subprocess.py:93} INFO - 23/05/29 10:31:39 INFO DAGScheduler: Parents of final stage: List()
[2023-05-29T10:31:39.933+0000] {subprocess.py:93} INFO - 23/05/29 10:31:39 INFO DAGScheduler: Missing parents: List()
[2023-05-29T10:31:39.940+0000] {subprocess.py:93} INFO - 23/05/29 10:31:39 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
[2023-05-29T10:31:40.424+0000] {subprocess.py:93} INFO - 23/05/29 10:31:40 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 103.6 KiB, free 434.3 MiB)
[2023-05-29T10:31:40.650+0000] {subprocess.py:93} INFO - 23/05/29 10:31:40 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 434.3 MiB)
[2023-05-29T10:31:40.656+0000] {subprocess.py:93} INFO - 23/05/29 10:31:40 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 4b5d28de6f1c.mylabserver.com:39921 (size: 37.3 KiB, free: 434.4 MiB)
[2023-05-29T10:31:40.667+0000] {subprocess.py:93} INFO - 23/05/29 10:31:40 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1535
[2023-05-29T10:31:40.824+0000] {subprocess.py:93} INFO - 23/05/29 10:31:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2023-05-29T10:31:40.826+0000] {subprocess.py:93} INFO - 23/05/29 10:31:40 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2023-05-29T10:31:41.136+0000] {subprocess.py:93} INFO - 23/05/29 10:31:41 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (4b5d28de6f1c.mylabserver.com, executor driver, partition 0, PROCESS_LOCAL, 7617 bytes)
[2023-05-29T10:31:41.228+0000] {subprocess.py:93} INFO - 23/05/29 10:31:41 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2023-05-29T10:31:43.612+0000] {subprocess.py:93} INFO - 23/05/29 10:31:43 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2218 bytes result sent to driver
[2023-05-29T10:31:43.633+0000] {subprocess.py:93} INFO - 23/05/29 10:31:43 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2636 ms on 4b5d28de6f1c.mylabserver.com (executor driver) (1/1)
[2023-05-29T10:31:43.778+0000] {subprocess.py:93} INFO - 23/05/29 10:31:43 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2023-05-29T10:31:43.778+0000] {subprocess.py:93} INFO - 23/05/29 10:31:43 INFO DAGScheduler: ResultStage 0 (parquet at NativeMethodAccessorImpl.java:0) finished in 3.682 s
[2023-05-29T10:31:43.778+0000] {subprocess.py:93} INFO - 23/05/29 10:31:43 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2023-05-29T10:31:43.778+0000] {subprocess.py:93} INFO - 23/05/29 10:31:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
[2023-05-29T10:31:43.784+0000] {subprocess.py:93} INFO - 23/05/29 10:31:43 INFO DAGScheduler: Job 0 finished: parquet at NativeMethodAccessorImpl.java:0, took 3.987829 s
[2023-05-29T10:31:45.548+0000] {subprocess.py:93} INFO - 23/05/29 10:31:45 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 4b5d28de6f1c.mylabserver.com:39921 in memory (size: 37.3 KiB, free: 434.4 MiB)
[2023-05-29T10:31:57.460+0000] {subprocess.py:93} INFO - 23/05/29 10:31:57 INFO FileSourceStrategy: Pushed Filters:
[2023-05-29T10:31:57.463+0000] {subprocess.py:93} INFO - 23/05/29 10:31:57 INFO FileSourceStrategy: Post-Scan Filters:
[2023-05-29T10:32:01.075+0000] {subprocess.py:93} INFO - 23/05/29 10:32:01 INFO CodeGenerator: Code generated in 1295.670422 ms
[2023-05-29T10:32:01.297+0000] {subprocess.py:93} INFO - 23/05/29 10:32:01 INFO CodeGenerator: Code generated in 153.81581 ms
[2023-05-29T10:32:01.939+0000] {subprocess.py:93} INFO - 23/05/29 10:32:01 INFO CodeGenerator: Code generated in 551.371194 ms
[2023-05-29T10:32:02.261+0000] {subprocess.py:93} INFO - 23/05/29 10:32:02 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 202.8 KiB, free 434.2 MiB)
[2023-05-29T10:32:02.333+0000] {subprocess.py:93} INFO - 23/05/29 10:32:02 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 434.2 MiB)
[2023-05-29T10:32:02.336+0000] {subprocess.py:93} INFO - 23/05/29 10:32:02 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 4b5d28de6f1c.mylabserver.com:39921 (size: 35.3 KiB, free: 434.4 MiB)
[2023-05-29T10:32:02.340+0000] {subprocess.py:93} INFO - 23/05/29 10:32:02 INFO SparkContext: Created broadcast 1 from parquet at NativeMethodAccessorImpl.java:0
[2023-05-29T10:32:02.417+0000] {subprocess.py:93} INFO - 23/05/29 10:32:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 58809804 bytes, open cost is considered as scanning 4194304 bytes.
[2023-05-29T10:32:03.548+0000] {subprocess.py:93} INFO - 23/05/29 10:32:03 INFO DAGScheduler: Registering RDD 5 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2023-05-29T10:32:03.622+0000] {subprocess.py:93} INFO - 23/05/29 10:32:03 INFO DAGScheduler: Registering RDD 16 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 1
[2023-05-29T10:32:03.623+0000] {subprocess.py:93} INFO - 23/05/29 10:32:03 INFO DAGScheduler: Got map stage job 1 (parquet at NativeMethodAccessorImpl.java:0) with 4 output partitions
[2023-05-29T10:32:03.624+0000] {subprocess.py:93} INFO - 23/05/29 10:32:03 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (parquet at NativeMethodAccessorImpl.java:0)
[2023-05-29T10:32:03.625+0000] {subprocess.py:93} INFO - 23/05/29 10:32:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
[2023-05-29T10:32:03.631+0000] {subprocess.py:93} INFO - 23/05/29 10:32:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
[2023-05-29T10:32:03.701+0000] {subprocess.py:93} INFO - 23/05/29 10:32:03 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
[2023-05-29T10:32:03.783+0000] {subprocess.py:93} INFO - 23/05/29 10:32:03 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 22.4 KiB, free 434.1 MiB)
[2023-05-29T10:32:03.941+0000] {subprocess.py:93} INFO - 23/05/29 10:32:03 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 434.1 MiB)
[2023-05-29T10:32:03.943+0000] {subprocess.py:93} INFO - 23/05/29 10:32:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 4b5d28de6f1c.mylabserver.com:39921 (size: 9.2 KiB, free: 434.4 MiB)
[2023-05-29T10:32:03.948+0000] {subprocess.py:93} INFO - 23/05/29 10:32:03 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1535
[2023-05-29T10:32:03.948+0000] {subprocess.py:93} INFO - 23/05/29 10:32:03 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2023-05-29T10:32:03.948+0000] {subprocess.py:93} INFO - 23/05/29 10:32:03 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks resource profile 0
[2023-05-29T10:32:04.012+0000] {subprocess.py:93} INFO - 23/05/29 10:32:04 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (4b5d28de6f1c.mylabserver.com, executor driver, partition 0, PROCESS_LOCAL, 8882 bytes)
[2023-05-29T10:32:04.021+0000] {subprocess.py:93} INFO - 23/05/29 10:32:04 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (4b5d28de6f1c.mylabserver.com, executor driver, partition 1, PROCESS_LOCAL, 8882 bytes)
[2023-05-29T10:32:04.021+0000] {subprocess.py:93} INFO - 23/05/29 10:32:04 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
[2023-05-29T10:32:04.025+0000] {subprocess.py:93} INFO - 23/05/29 10:32:04 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
[2023-05-29T10:32:04.751+0000] {subprocess.py:93} INFO - 23/05/29 10:32:04 INFO CodeGenerator: Code generated in 335.221866 ms
[2023-05-29T10:32:04.892+0000] {subprocess.py:93} INFO - 23/05/29 10:32:04 INFO FileScanRDD: Reading File path: file:///home/cloud_user/Stock-Market-Nasdaq/data/processed_data/parquet_format/stocks.parquet/part-00005-3129964c-4655-41d3-83e1-2d1a33041542-c000.snappy.parquet, range: 0-7571949, partition values: [empty row]
[2023-05-29T10:32:04.892+0000] {subprocess.py:93} INFO - 23/05/29 10:32:04 INFO FileScanRDD: Reading File path: file:///home/cloud_user/Stock-Market-Nasdaq/data/processed_data/parquet_format/stocks.parquet/part-00004-3129964c-4655-41d3-83e1-2d1a33041542-c000.snappy.parquet, range: 0-7568147, partition values: [empty row]
[2023-05-29T10:32:06.343+0000] {subprocess.py:93} INFO - 23/05/29 10:32:06 INFO CodecPool: Got brand-new decompressor [.snappy]
[2023-05-29T10:32:06.347+0000] {subprocess.py:93} INFO - 23/05/29 10:32:06 INFO CodecPool: Got brand-new decompressor [.snappy]
[2023-05-29T10:32:20.582+0000] {subprocess.py:93} INFO - 23/05/29 10:32:20 INFO FileScanRDD: Reading File path: file:///home/cloud_user/Stock-Market-Nasdaq/data/processed_data/parquet_format/stocks.parquet/part-00000-3129964c-4655-41d3-83e1-2d1a33041542-c000.snappy.parquet, range: 0-7571242, partition values: [empty row]
[2023-05-29T10:32:20.812+0000] {subprocess.py:93} INFO - 23/05/29 10:32:20 INFO FileScanRDD: Reading File path: file:///home/cloud_user/Stock-Market-Nasdaq/data/processed_data/parquet_format/stocks.parquet/part-00006-3129964c-4655-41d3-83e1-2d1a33041542-c000.snappy.parquet, range: 0-7565905, partition values: [empty row]
[2023-05-29T10:32:26.354+0000] {subprocess.py:93} INFO - 23/05/29 10:32:26 INFO FileScanRDD: Reading File path: file:///home/cloud_user/Stock-Market-Nasdaq/data/processed_data/parquet_format/stocks.parquet/part-00009-3129964c-4655-41d3-83e1-2d1a33041542-c000.snappy.parquet, range: 0-7569637, partition values: [empty row]
[2023-05-29T10:32:26.421+0000] {subprocess.py:93} INFO - 23/05/29 10:32:26 INFO FileScanRDD: Reading File path: file:///home/cloud_user/Stock-Market-Nasdaq/data/processed_data/parquet_format/stocks.parquet/part-00008-3129964c-4655-41d3-83e1-2d1a33041542-c000.snappy.parquet, range: 0-7564158, partition values: [empty row]
[2023-05-29T10:32:31.932+0000] {subprocess.py:93} INFO - 23/05/29 10:32:31 INFO FileScanRDD: Reading File path: file:///home/cloud_user/Stock-Market-Nasdaq/data/processed_data/parquet_format/stocks.parquet/part-00007-3129964c-4655-41d3-83e1-2d1a33041542-c000.snappy.parquet, range: 0-7564061, partition values: [empty row]
[2023-05-29T10:32:32.274+0000] {subprocess.py:93} INFO - 23/05/29 10:32:32 INFO FileScanRDD: Reading File path: file:///home/cloud_user/Stock-Market-Nasdaq/data/processed_data/parquet_format/stocks.parquet/part-00003-3129964c-4655-41d3-83e1-2d1a33041542-c000.snappy.parquet, range: 0-7568863, partition values: [empty row]
[2023-05-29T10:32:37.138+0000] {subprocess.py:93} INFO - 23/05/29 10:32:37 INFO FileScanRDD: Reading File path: file:///home/cloud_user/Stock-Market-Nasdaq/data/processed_data/parquet_format/stocks.parquet/part-00002-3129964c-4655-41d3-83e1-2d1a33041542-c000.snappy.parquet, range: 0-7563789, partition values: [empty row]
[2023-05-29T10:32:37.772+0000] {subprocess.py:93} INFO - 23/05/29 10:32:37 INFO FileScanRDD: Reading File path: file:///home/cloud_user/Stock-Market-Nasdaq/data/processed_data/parquet_format/stocks.parquet/part-00001-3129964c-4655-41d3-83e1-2d1a33041542-c000.snappy.parquet, range: 0-7568817, partition values: [empty row]
[2023-05-29T10:32:46.107+0000] {subprocess.py:93} INFO - 23/05/29 10:32:46 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2100 bytes result sent to driver
[2023-05-29T10:32:46.178+0000] {subprocess.py:93} INFO - 23/05/29 10:32:46 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 42229 ms on 4b5d28de6f1c.mylabserver.com (executor driver) (1/2)
[2023-05-29T10:32:46.499+0000] {subprocess.py:93} INFO - 23/05/29 10:32:46 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 2100 bytes result sent to driver
[2023-05-29T10:32:46.504+0000] {subprocess.py:93} INFO - 23/05/29 10:32:46 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 42489 ms on 4b5d28de6f1c.mylabserver.com (executor driver) (2/2)
[2023-05-29T10:32:46.507+0000] {subprocess.py:93} INFO - 23/05/29 10:32:46 INFO DAGScheduler: ShuffleMapStage 1 (parquet at NativeMethodAccessorImpl.java:0) finished in 42.735 s
[2023-05-29T10:32:46.507+0000] {subprocess.py:93} INFO - 23/05/29 10:32:46 INFO DAGScheduler: looking for newly runnable stages
[2023-05-29T10:32:46.508+0000] {subprocess.py:93} INFO - 23/05/29 10:32:46 INFO DAGScheduler: running: Set()
[2023-05-29T10:32:46.508+0000] {subprocess.py:93} INFO - 23/05/29 10:32:46 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2)
[2023-05-29T10:32:46.513+0000] {subprocess.py:93} INFO - 23/05/29 10:32:46 INFO DAGScheduler: failed: Set()
[2023-05-29T10:32:46.572+0000] {subprocess.py:93} INFO - 23/05/29 10:32:46 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2023-05-29T10:32:46.574+0000] {subprocess.py:93} INFO - 23/05/29 10:32:46 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
[2023-05-29T10:32:46.823+0000] {subprocess.py:93} INFO - 23/05/29 10:32:46 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 48.2 KiB, free 434.1 MiB)
[2023-05-29T10:32:46.826+0000] {subprocess.py:93} INFO - 23/05/29 10:32:46 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 21.9 KiB, free 434.1 MiB)
[2023-05-29T10:32:46.827+0000] {subprocess.py:93} INFO - 23/05/29 10:32:46 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 4b5d28de6f1c.mylabserver.com:39921 (size: 21.9 KiB, free: 434.3 MiB)
[2023-05-29T10:32:46.829+0000] {subprocess.py:93} INFO - 23/05/29 10:32:46 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
[2023-05-29T10:32:46.831+0000] {subprocess.py:93} INFO - 23/05/29 10:32:46 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2023-05-29T10:32:46.832+0000] {subprocess.py:93} INFO - 23/05/29 10:32:46 INFO TaskSchedulerImpl: Adding task set 2.0 with 4 tasks resource profile 0
[2023-05-29T10:32:46.904+0000] {subprocess.py:93} INFO - 23/05/29 10:32:46 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 3) (4b5d28de6f1c.mylabserver.com, executor driver, partition 0, NODE_LOCAL, 7352 bytes)
[2023-05-29T10:32:46.905+0000] {subprocess.py:93} INFO - 23/05/29 10:32:46 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 4) (4b5d28de6f1c.mylabserver.com, executor driver, partition 1, NODE_LOCAL, 7352 bytes)
[2023-05-29T10:32:46.912+0000] {subprocess.py:93} INFO - 23/05/29 10:32:46 INFO Executor: Running task 0.0 in stage 2.0 (TID 3)
[2023-05-29T10:32:46.912+0000] {subprocess.py:93} INFO - 23/05/29 10:32:46 INFO Executor: Running task 1.0 in stage 2.0 (TID 4)
[2023-05-29T10:32:47.390+0000] {subprocess.py:93} INFO - 23/05/29 10:32:47 INFO ShuffleBlockFetcherIterator: Getting 2 (38.6 MiB) non-empty blocks including 2 (38.6 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-05-29T10:32:47.394+0000] {subprocess.py:93} INFO - 23/05/29 10:32:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 20 ms
[2023-05-29T10:32:47.473+0000] {subprocess.py:93} INFO - 23/05/29 10:32:47 INFO ShuffleBlockFetcherIterator: Getting 2 (33.4 MiB) non-empty blocks including 2 (33.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-05-29T10:32:47.541+0000] {subprocess.py:93} INFO - 23/05/29 10:32:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
[2023-05-29T10:32:47.554+0000] {subprocess.py:93} INFO - 23/05/29 10:32:47 INFO CodeGenerator: Code generated in 78.852279 ms
[2023-05-29T10:32:47.700+0000] {subprocess.py:93} INFO - 23/05/29 10:32:47 INFO CodeGenerator: Code generated in 77.567824 ms
[2023-05-29T10:32:48.013+0000] {subprocess.py:93} INFO - 23/05/29 10:32:48 INFO CodeGenerator: Code generated in 150.4901 ms
[2023-05-29T10:32:48.034+0000] {subprocess.py:93} INFO - 23/05/29 10:32:48 INFO CodeGenerator: Code generated in 15.482639 ms
[2023-05-29T10:32:50.828+0000] {subprocess.py:93} INFO - 23/05/29 10:32:50 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 4b5d28de6f1c.mylabserver.com:39921 in memory (size: 9.2 KiB, free: 434.3 MiB)
[2023-05-29T10:32:59.471+0000] {subprocess.py:93} INFO - 23/05/29 10:32:59 INFO CodeGenerator: Code generated in 89.702353 ms
[2023-05-29T10:32:59.793+0000] {subprocess.py:93} INFO - 23/05/29 10:32:59 INFO CodeGenerator: Code generated in 85.616794 ms
[2023-05-29T10:33:00.031+0000] {subprocess.py:93} INFO - 23/05/29 10:33:00 INFO CodeGenerator: Code generated in 91.792879 ms
[2023-05-29T10:33:00.259+0000] {subprocess.py:93} INFO - 23/05/29 10:33:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:33:20.493+0000] {subprocess.py:93} INFO - 23/05/29 10:33:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:33:47.947+0000] {subprocess.py:93} INFO - 23/05/29 10:33:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:33:55.302+0000] {subprocess.py:93} INFO - 23/05/29 10:33:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:34:13.477+0000] {subprocess.py:93} INFO - 23/05/29 10:34:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:34:20.818+0000] {subprocess.py:93} INFO - 23/05/29 10:34:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:34:36.349+0000] {subprocess.py:93} INFO - 23/05/29 10:34:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:35:00.027+0000] {subprocess.py:93} INFO - 23/05/29 10:35:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:35:15.793+0000] {subprocess.py:93} INFO - 23/05/29 10:35:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:35:24.432+0000] {subprocess.py:93} INFO - 23/05/29 10:35:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:35:31.790+0000] {subprocess.py:93} INFO - 23/05/29 10:35:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:35:59.081+0000] {subprocess.py:93} INFO - 23/05/29 10:35:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:36:05.636+0000] {subprocess.py:93} INFO - 23/05/29 10:36:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:36:16.029+0000] {subprocess.py:93} INFO - 23/05/29 10:36:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:36:24.026+0000] {subprocess.py:93} INFO - 23/05/29 10:36:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:36:27.079+0000] {subprocess.py:93} INFO - 23/05/29 10:36:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:36:46.361+0000] {subprocess.py:93} INFO - 23/05/29 10:36:46 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:36:53.464+0000] {subprocess.py:93} INFO - 23/05/29 10:36:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:37:00.124+0000] {subprocess.py:93} INFO - 23/05/29 10:37:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:37:26.042+0000] {subprocess.py:93} INFO - 23/05/29 10:37:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:37:43.086+0000] {subprocess.py:93} INFO - 23/05/29 10:37:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:38:09.879+0000] {subprocess.py:93} INFO - 23/05/29 10:38:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:38:15.556+0000] {subprocess.py:93} INFO - 23/05/29 10:38:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:38:27.474+0000] {subprocess.py:93} INFO - 23/05/29 10:38:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:38:29.328+0000] {subprocess.py:93} INFO - 23/05/29 10:38:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:38:40.445+0000] {subprocess.py:93} INFO - 23/05/29 10:38:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:38:50.596+0000] {subprocess.py:93} INFO - 23/05/29 10:38:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:38:54.915+0000] {subprocess.py:93} INFO - 23/05/29 10:38:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:39:10.430+0000] {subprocess.py:93} INFO - 23/05/29 10:39:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:39:15.788+0000] {subprocess.py:93} INFO - 23/05/29 10:39:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:39:25.397+0000] {subprocess.py:93} INFO - 23/05/29 10:39:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:39:59.474+0000] {subprocess.py:93} INFO - 23/05/29 10:39:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:40:08.603+0000] {subprocess.py:93} INFO - 23/05/29 10:40:08 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:40:26.933+0000] {subprocess.py:93} INFO - 23/05/29 10:40:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:40:40.850+0000] {subprocess.py:93} INFO - 23/05/29 10:40:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:40:41.562+0000] {subprocess.py:93} INFO - 23/05/29 10:40:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:40:55.014+0000] {subprocess.py:93} INFO - 23/05/29 10:40:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:41:14.610+0000] {subprocess.py:93} INFO - 23/05/29 10:41:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:41:32.045+0000] {subprocess.py:93} INFO - 23/05/29 10:41:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:41:58.841+0000] {subprocess.py:93} INFO - 23/05/29 10:41:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:42:09.244+0000] {subprocess.py:93} INFO - 23/05/29 10:42:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:42:15.094+0000] {subprocess.py:93} INFO - 23/05/29 10:42:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:42:18.855+0000] {subprocess.py:93} INFO - 23/05/29 10:42:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:42:41.491+0000] {subprocess.py:93} INFO - 23/05/29 10:42:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:42:47.961+0000] {subprocess.py:93} INFO - 23/05/29 10:42:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:42:55.404+0000] {subprocess.py:93} INFO - 23/05/29 10:42:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:43:07.723+0000] {subprocess.py:93} INFO - 23/05/29 10:43:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:43:17.017+0000] {subprocess.py:93} INFO - 23/05/29 10:43:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:43:17.099+0000] {subprocess.py:93} INFO - 23/05/29 10:43:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:43:31.900+0000] {subprocess.py:93} INFO - 23/05/29 10:43:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:43:57.898+0000] {subprocess.py:93} INFO - 23/05/29 10:43:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:44:23.562+0000] {subprocess.py:93} INFO - 23/05/29 10:44:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:44:28.135+0000] {subprocess.py:93} INFO - 23/05/29 10:44:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:44:49.568+0000] {subprocess.py:93} INFO - 23/05/29 10:44:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:45:03.971+0000] {subprocess.py:93} INFO - 23/05/29 10:45:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:45:11.971+0000] {subprocess.py:93} INFO - 23/05/29 10:45:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:45:29.729+0000] {subprocess.py:93} INFO - 23/05/29 10:45:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:45:30.691+0000] {subprocess.py:93} INFO - 23/05/29 10:45:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:45:45.585+0000] {subprocess.py:93} INFO - 23/05/29 10:45:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:46:03.811+0000] {subprocess.py:93} INFO - 23/05/29 10:46:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:46:08.929+0000] {subprocess.py:93} INFO - 23/05/29 10:46:08 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:46:17.427+0000] {subprocess.py:93} INFO - 23/05/29 10:46:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:46:25.886+0000] {subprocess.py:93} INFO - 23/05/29 10:46:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:46:26.530+0000] {subprocess.py:93} INFO - 23/05/29 10:46:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:46:35.647+0000] {subprocess.py:93} INFO - 23/05/29 10:46:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:46:43.732+0000] {subprocess.py:93} INFO - 23/05/29 10:46:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:46:49.670+0000] {subprocess.py:93} INFO - 23/05/29 10:46:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:47:04.447+0000] {subprocess.py:93} INFO - 23/05/29 10:47:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:47:13.108+0000] {subprocess.py:93} INFO - 23/05/29 10:47:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:47:24.289+0000] {subprocess.py:93} INFO - 23/05/29 10:47:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:47:37.107+0000] {subprocess.py:93} INFO - 23/05/29 10:47:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:47:37.809+0000] {subprocess.py:93} INFO - 23/05/29 10:47:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:47:51.577+0000] {subprocess.py:93} INFO - 23/05/29 10:47:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:48:10.936+0000] {subprocess.py:93} INFO - 23/05/29 10:48:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:48:25.823+0000] {subprocess.py:93} INFO - 23/05/29 10:48:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:48:26.701+0000] {subprocess.py:93} INFO - 23/05/29 10:48:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:48:34.070+0000] {subprocess.py:93} INFO - 23/05/29 10:48:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:48:39.738+0000] {subprocess.py:93} INFO - 23/05/29 10:48:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:48:51.898+0000] {subprocess.py:93} INFO - 23/05/29 10:48:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:49:02.228+0000] {subprocess.py:93} INFO - 23/05/29 10:49:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:49:11.275+0000] {subprocess.py:93} INFO - 23/05/29 10:49:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:49:19.987+0000] {subprocess.py:93} INFO - 23/05/29 10:49:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:49:21.670+0000] {subprocess.py:93} INFO - 23/05/29 10:49:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:49:25.653+0000] {subprocess.py:93} INFO - 23/05/29 10:49:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:49:36.867+0000] {subprocess.py:93} INFO - 23/05/29 10:49:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:49:46.871+0000] {subprocess.py:93} INFO - 23/05/29 10:49:46 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:50:00.072+0000] {subprocess.py:93} INFO - 23/05/29 10:50:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:50:26.305+0000] {subprocess.py:93} INFO - 23/05/29 10:50:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:50:31.585+0000] {subprocess.py:93} INFO - 23/05/29 10:50:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:50:57.760+0000] {subprocess.py:93} INFO - 23/05/29 10:50:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:51:04.317+0000] {subprocess.py:93} INFO - 23/05/29 10:51:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:51:18.470+0000] {subprocess.py:93} INFO - 23/05/29 10:51:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:51:29.920+0000] {subprocess.py:93} INFO - 23/05/29 10:51:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:51:40.467+0000] {subprocess.py:93} INFO - 23/05/29 10:51:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:51:41.522+0000] {subprocess.py:93} INFO - 23/05/29 10:51:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:51:56.715+0000] {subprocess.py:93} INFO - 23/05/29 10:51:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:52:07.442+0000] {subprocess.py:93} INFO - 23/05/29 10:52:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:52:13.187+0000] {subprocess.py:93} INFO - 23/05/29 10:52:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:52:18.240+0000] {subprocess.py:93} INFO - 23/05/29 10:52:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:52:26.701+0000] {subprocess.py:93} INFO - 23/05/29 10:52:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:52:35.113+0000] {subprocess.py:93} INFO - 23/05/29 10:52:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:53:11.505+0000] {subprocess.py:93} INFO - 23/05/29 10:53:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:53:13.677+0000] {subprocess.py:93} INFO - 23/05/29 10:53:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:53:30.069+0000] {subprocess.py:93} INFO - 23/05/29 10:53:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:53:38.230+0000] {subprocess.py:93} INFO - 23/05/29 10:53:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:53:54.403+0000] {subprocess.py:93} INFO - 23/05/29 10:53:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:54:11.281+0000] {subprocess.py:93} INFO - 23/05/29 10:54:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:54:19.668+0000] {subprocess.py:93} INFO - 23/05/29 10:54:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:54:28.229+0000] {subprocess.py:93} INFO - 23/05/29 10:54:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:54:37.923+0000] {subprocess.py:93} INFO - 23/05/29 10:54:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:54:51.209+0000] {subprocess.py:93} INFO - 23/05/29 10:54:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:54:52.469+0000] {subprocess.py:93} INFO - 23/05/29 10:54:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:55:02.386+0000] {subprocess.py:93} INFO - 23/05/29 10:55:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:55:15.995+0000] {subprocess.py:93} INFO - 23/05/29 10:55:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:55:29.690+0000] {subprocess.py:93} INFO - 23/05/29 10:55:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:55:30.967+0000] {subprocess.py:93} INFO - 23/05/29 10:55:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:55:50.091+0000] {subprocess.py:93} INFO - 23/05/29 10:55:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:55:54.868+0000] {subprocess.py:93} INFO - 23/05/29 10:55:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:55:59.277+0000] {subprocess.py:93} INFO - 23/05/29 10:55:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:56:08.884+0000] {subprocess.py:93} INFO - 23/05/29 10:56:08 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:56:25.283+0000] {subprocess.py:93} INFO - 23/05/29 10:56:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:56:35.851+0000] {subprocess.py:93} INFO - 23/05/29 10:56:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:56:48.875+0000] {subprocess.py:93} INFO - 23/05/29 10:56:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:56:58.391+0000] {subprocess.py:93} INFO - 23/05/29 10:56:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:57:08.571+0000] {subprocess.py:93} INFO - 23/05/29 10:57:08 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:57:10.723+0000] {subprocess.py:93} INFO - 23/05/29 10:57:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:57:20.163+0000] {subprocess.py:93} INFO - 23/05/29 10:57:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:57:31.128+0000] {subprocess.py:93} INFO - 23/05/29 10:57:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:57:40.969+0000] {subprocess.py:93} INFO - 23/05/29 10:57:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:57:53.134+0000] {subprocess.py:93} INFO - 23/05/29 10:57:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:58:02.814+0000] {subprocess.py:93} INFO - 23/05/29 10:58:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:58:14.243+0000] {subprocess.py:93} INFO - 23/05/29 10:58:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:58:15.999+0000] {subprocess.py:93} INFO - 23/05/29 10:58:15 INFO MemoryStore: Will not store rdd_11_0
[2023-05-29T10:58:16.001+0000] {subprocess.py:93} INFO - 23/05/29 10:58:16 WARN MemoryStore: Not enough space to cache rdd_11_0 in memory! (computed 29.5 MiB so far)
[2023-05-29T10:58:16.004+0000] {subprocess.py:93} INFO - 23/05/29 10:58:16 INFO MemoryStore: Memory use = 308.2 KiB (blocks) + 45.2 MiB (scratch space shared across 2 tasks(s)) = 45.5 MiB. Storage limit = 65.9 MiB.
[2023-05-29T10:58:16.009+0000] {subprocess.py:93} INFO - 23/05/29 10:58:16 WARN BlockManager: Persisting block rdd_11_0 to disk instead.
[2023-05-29T10:58:19.045+0000] {subprocess.py:93} INFO - 23/05/29 10:58:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:58:24.487+0000] {subprocess.py:93} INFO - 23/05/29 10:58:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:58:36.638+0000] {subprocess.py:93} INFO - 23/05/29 10:58:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:58:39.929+0000] {subprocess.py:93} INFO - 23/05/29 10:58:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:58:48.166+0000] {subprocess.py:93} INFO - 23/05/29 10:58:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:59:05.117+0000] {subprocess.py:93} INFO - 23/05/29 10:59:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:59:06.328+0000] {subprocess.py:93} INFO - 23/05/29 10:59:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:59:18.424+0000] {subprocess.py:93} INFO - 23/05/29 10:59:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:59:37.214+0000] {subprocess.py:93} INFO - 23/05/29 10:59:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:59:48.241+0000] {subprocess.py:93} INFO - 23/05/29 10:59:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T10:59:50.016+0000] {subprocess.py:93} INFO - 23/05/29 10:59:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:00:11.774+0000] {subprocess.py:93} INFO - 23/05/29 11:00:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:00:17.522+0000] {subprocess.py:93} INFO - 23/05/29 11:00:17 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:00:22.331+0000] {subprocess.py:93} INFO - 23/05/29 11:00:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:00:28.883+0000] {subprocess.py:93} INFO - 23/05/29 11:00:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:00:47.382+0000] {subprocess.py:93} INFO - 23/05/29 11:00:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:00:52.012+0000] {subprocess.py:93} INFO - 23/05/29 11:00:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:01:13.928+0000] {subprocess.py:93} INFO - 23/05/29 11:01:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:01:24.419+0000] {subprocess.py:93} INFO - 23/05/29 11:01:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:01:26.006+0000] {subprocess.py:93} INFO - 23/05/29 11:01:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:01:32.093+0000] {subprocess.py:93} INFO - 23/05/29 11:01:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:01:46.576+0000] {subprocess.py:93} INFO - 23/05/29 11:01:46 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:02:04.650+0000] {subprocess.py:93} INFO - 23/05/29 11:02:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:02:12.186+0000] {subprocess.py:93} INFO - 23/05/29 11:02:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:02:13.287+0000] {subprocess.py:93} INFO - 23/05/29 11:02:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:02:18.492+0000] {subprocess.py:93} INFO - 23/05/29 11:02:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:02:29.450+0000] {subprocess.py:93} INFO - 23/05/29 11:02:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:02:39.288+0000] {subprocess.py:93} INFO - 23/05/29 11:02:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:02:47.705+0000] {subprocess.py:93} INFO - 23/05/29 11:02:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:02:52.906+0000] {subprocess.py:93} INFO - 23/05/29 11:02:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:03:09.049+0000] {subprocess.py:93} INFO - 23/05/29 11:03:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:03:24.907+0000] {subprocess.py:93} INFO - 23/05/29 11:03:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:03:44.576+0000] {subprocess.py:93} INFO - 23/05/29 11:03:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:03:46.272+0000] {subprocess.py:93} INFO - 23/05/29 11:03:46 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:03:58.272+0000] {subprocess.py:93} INFO - 23/05/29 11:03:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:04:09.625+0000] {subprocess.py:93} INFO - 23/05/29 11:04:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:04:10.982+0000] {subprocess.py:93} INFO - 23/05/29 11:04:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:04:23.941+0000] {subprocess.py:93} INFO - 23/05/29 11:04:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:04:48.013+0000] {subprocess.py:93} INFO - 23/05/29 11:04:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:04:58.665+0000] {subprocess.py:93} INFO - 23/05/29 11:04:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:04:59.948+0000] {subprocess.py:93} INFO - 23/05/29 11:04:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:05:32.425+0000] {subprocess.py:93} INFO - 23/05/29 11:05:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:05:35.214+0000] {subprocess.py:93} INFO - 23/05/29 11:05:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:05:44.585+0000] {subprocess.py:93} INFO - 23/05/29 11:05:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:06:14.196+0000] {subprocess.py:93} INFO - 23/05/29 11:06:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:06:20.903+0000] {subprocess.py:93} INFO - 23/05/29 11:06:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:06:24.831+0000] {subprocess.py:93} INFO - 23/05/29 11:06:24 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:06:41.866+0000] {subprocess.py:93} INFO - 23/05/29 11:06:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:06:59.228+0000] {subprocess.py:93} INFO - 23/05/29 11:06:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:07:18.998+0000] {subprocess.py:93} INFO - 23/05/29 11:07:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:07:22.581+0000] {subprocess.py:93} INFO - 23/05/29 11:07:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:07:33.552+0000] {subprocess.py:93} INFO - 23/05/29 11:07:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:07:35.959+0000] {subprocess.py:93} INFO - 23/05/29 11:07:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:07:50.018+0000] {subprocess.py:93} INFO - 23/05/29 11:07:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:07:52.108+0000] {subprocess.py:93} INFO - 23/05/29 11:07:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:08:02.352+0000] {subprocess.py:93} INFO - 23/05/29 11:08:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:08:19.388+0000] {subprocess.py:93} INFO - 23/05/29 11:08:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:08:21.461+0000] {subprocess.py:93} INFO - 23/05/29 11:08:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:08:36.923+0000] {subprocess.py:93} INFO - 23/05/29 11:08:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:08:51.004+0000] {subprocess.py:93} INFO - 23/05/29 11:08:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:08:53.637+0000] {subprocess.py:93} INFO - 23/05/29 11:08:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:09:04.038+0000] {subprocess.py:93} INFO - 23/05/29 11:09:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:09:26.911+0000] {subprocess.py:93} INFO - 23/05/29 11:09:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:09:38.672+0000] {subprocess.py:93} INFO - 23/05/29 11:09:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:09:47.791+0000] {subprocess.py:93} INFO - 23/05/29 11:09:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:10:04.511+0000] {subprocess.py:93} INFO - 23/05/29 11:10:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:10:13.469+0000] {subprocess.py:93} INFO - 23/05/29 11:10:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:10:22.447+0000] {subprocess.py:93} INFO - 23/05/29 11:10:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:10:29.159+0000] {subprocess.py:93} INFO - 23/05/29 11:10:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:10:55.482+0000] {subprocess.py:93} INFO - 23/05/29 11:10:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:11:02.111+0000] {subprocess.py:93} INFO - 23/05/29 11:11:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:11:07.561+0000] {subprocess.py:93} INFO - 23/05/29 11:11:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:11:25.639+0000] {subprocess.py:93} INFO - 23/05/29 11:11:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:11:27.234+0000] {subprocess.py:93} INFO - 23/05/29 11:11:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:11:39.080+0000] {subprocess.py:93} INFO - 23/05/29 11:11:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:11:52.519+0000] {subprocess.py:93} INFO - 23/05/29 11:11:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:12:09.482+0000] {subprocess.py:93} INFO - 23/05/29 11:12:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:12:13.633+0000] {subprocess.py:93} INFO - 23/05/29 11:12:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:12:22.035+0000] {subprocess.py:93} INFO - 23/05/29 11:12:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:12:25.407+0000] {subprocess.py:93} INFO - 23/05/29 11:12:25 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:12:49.232+0000] {subprocess.py:93} INFO - 23/05/29 11:12:49 INFO BlockManagerInfo: Added rdd_11_0 on disk on 4b5d28de6f1c.mylabserver.com:39921 (size: 30.5 MiB)
[2023-05-29T11:12:50.357+0000] {subprocess.py:93} INFO - 23/05/29 11:12:50 INFO MemoryStore: Block rdd_11_0 stored as values in memory (estimated size 46.8 MiB, free 195.1 MiB)
[2023-05-29T11:12:50.370+0000] {subprocess.py:93} INFO - 23/05/29 11:12:50 INFO CodeGenerator: Code generated in 7.342144 ms
[2023-05-29T11:12:50.611+0000] {subprocess.py:93} INFO - 23/05/29 11:12:50 INFO CodeGenerator: Code generated in 96.810825 ms
[2023-05-29T11:12:56.051+0000] {subprocess.py:93} INFO - 23/05/29 11:12:56 INFO UnsafeExternalSorter: Thread 73 spilling sort data of 136.0 MiB to disk (0  time so far)
[2023-05-29T11:13:01.241+0000] {subprocess.py:93} INFO - 23/05/29 11:13:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:13:16.209+0000] {subprocess.py:93} INFO - 23/05/29 11:13:16 INFO Executor: Finished task 0.0 in stage 2.0 (TID 3). 5333 bytes result sent to driver
[2023-05-29T11:13:16.357+0000] {subprocess.py:93} INFO - 23/05/29 11:13:16 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 5) (4b5d28de6f1c.mylabserver.com, executor driver, partition 2, NODE_LOCAL, 7352 bytes)
[2023-05-29T11:13:16.360+0000] {subprocess.py:93} INFO - 23/05/29 11:13:16 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 3) in 2429456 ms on 4b5d28de6f1c.mylabserver.com (executor driver) (1/4)
[2023-05-29T11:13:16.360+0000] {subprocess.py:93} INFO - 23/05/29 11:13:16 INFO Executor: Running task 2.0 in stage 2.0 (TID 5)
[2023-05-29T11:13:18.271+0000] {subprocess.py:93} INFO - 23/05/29 11:13:18 INFO ShuffleBlockFetcherIterator: Getting 2 (33.4 MiB) non-empty blocks including 2 (33.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-05-29T11:13:18.282+0000] {subprocess.py:93} INFO - 23/05/29 11:13:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 67 ms
[2023-05-29T11:13:27.877+0000] {subprocess.py:93} INFO - 23/05/29 11:13:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:13:37.968+0000] {subprocess.py:93} INFO - 23/05/29 11:13:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:13:44.361+0000] {subprocess.py:93} INFO - 23/05/29 11:13:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:13:53.723+0000] {subprocess.py:93} INFO - 23/05/29 11:13:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:14:12.055+0000] {subprocess.py:93} INFO - 23/05/29 11:14:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:14:19.640+0000] {subprocess.py:93} INFO - 23/05/29 11:14:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:14:34.616+0000] {subprocess.py:93} INFO - 23/05/29 11:14:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:14:46.361+0000] {subprocess.py:93} INFO - 23/05/29 11:14:46 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:14:50.927+0000] {subprocess.py:93} INFO - 23/05/29 11:14:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:15:00.680+0000] {subprocess.py:93} INFO - 23/05/29 11:15:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:15:03.408+0000] {subprocess.py:93} INFO - 23/05/29 11:15:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:15:10.371+0000] {subprocess.py:93} INFO - 23/05/29 11:15:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:15:22.455+0000] {subprocess.py:93} INFO - 23/05/29 11:15:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:15:29.098+0000] {subprocess.py:93} INFO - 23/05/29 11:15:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:15:34.923+0000] {subprocess.py:93} INFO - 23/05/29 11:15:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:15:48.602+0000] {subprocess.py:93} INFO - 23/05/29 11:15:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:15:57.404+0000] {subprocess.py:93} INFO - 23/05/29 11:15:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:16:09.018+0000] {subprocess.py:93} INFO - 23/05/29 11:16:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:16:14.858+0000] {subprocess.py:93} INFO - 23/05/29 11:16:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:16:28.055+0000] {subprocess.py:93} INFO - 23/05/29 11:16:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:16:35.328+0000] {subprocess.py:93} INFO - 23/05/29 11:16:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:16:52.528+0000] {subprocess.py:93} INFO - 23/05/29 11:16:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:16:56.442+0000] {subprocess.py:93} INFO - 23/05/29 11:16:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:16:58.617+0000] {subprocess.py:93} INFO - 23/05/29 11:16:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:17:04.607+0000] {subprocess.py:93} INFO - 23/05/29 11:17:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:17:08.604+0000] {subprocess.py:93} INFO - 23/05/29 11:17:08 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:17:16.682+0000] {subprocess.py:93} INFO - 23/05/29 11:17:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:17:18.447+0000] {subprocess.py:93} INFO - 23/05/29 11:17:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:17:40.445+0000] {subprocess.py:93} INFO - 23/05/29 11:17:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:17:43.104+0000] {subprocess.py:93} INFO - 23/05/29 11:17:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:17:57.017+0000] {subprocess.py:93} INFO - 23/05/29 11:17:57 INFO MemoryStore: Block rdd_11_1 stored as values in memory (estimated size 52.8 MiB, free 334.5 MiB)
[2023-05-29T11:17:57.018+0000] {subprocess.py:93} INFO - 23/05/29 11:17:57 INFO BlockManagerInfo: Added rdd_11_1 in memory on 4b5d28de6f1c.mylabserver.com:39921 (size: 52.8 MiB, free: 381.5 MiB)
[2023-05-29T11:18:06.206+0000] {subprocess.py:93} INFO - 23/05/29 11:18:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:18:11.350+0000] {subprocess.py:93} INFO - 23/05/29 11:18:11 INFO Executor: Finished task 1.0 in stage 2.0 (TID 4). 5333 bytes result sent to driver
[2023-05-29T11:18:11.413+0000] {subprocess.py:93} INFO - 23/05/29 11:18:11 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 6) (4b5d28de6f1c.mylabserver.com, executor driver, partition 3, NODE_LOCAL, 7352 bytes)
[2023-05-29T11:18:11.421+0000] {subprocess.py:93} INFO - 23/05/29 11:18:11 INFO Executor: Running task 3.0 in stage 2.0 (TID 6)
[2023-05-29T11:18:11.421+0000] {subprocess.py:93} INFO - 23/05/29 11:18:11 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 4) in 2724510 ms on 4b5d28de6f1c.mylabserver.com (executor driver) (2/4)
[2023-05-29T11:18:11.493+0000] {subprocess.py:93} INFO - 23/05/29 11:18:11 INFO ShuffleBlockFetcherIterator: Getting 2 (30.4 MiB) non-empty blocks including 2 (30.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-05-29T11:18:11.493+0000] {subprocess.py:93} INFO - 23/05/29 11:18:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2023-05-29T11:18:16.129+0000] {subprocess.py:93} INFO - 23/05/29 11:18:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:18:18.938+0000] {subprocess.py:93} INFO - 23/05/29 11:18:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:18:28.224+0000] {subprocess.py:93} INFO - 23/05/29 11:18:28 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:18:39.584+0000] {subprocess.py:93} INFO - 23/05/29 11:18:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:18:53.341+0000] {subprocess.py:93} INFO - 23/05/29 11:18:53 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:19:15.269+0000] {subprocess.py:93} INFO - 23/05/29 11:19:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:19:26.538+0000] {subprocess.py:93} INFO - 23/05/29 11:19:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:19:37.258+0000] {subprocess.py:93} INFO - 23/05/29 11:19:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:19:38.852+0000] {subprocess.py:93} INFO - 23/05/29 11:19:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:19:59.731+0000] {subprocess.py:93} INFO - 23/05/29 11:19:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:20:05.571+0000] {subprocess.py:93} INFO - 23/05/29 11:20:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:20:22.791+0000] {subprocess.py:93} INFO - 23/05/29 11:20:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:20:30.289+0000] {subprocess.py:93} INFO - 23/05/29 11:20:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:20:31.423+0000] {subprocess.py:93} INFO - 23/05/29 11:20:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:20:58.060+0000] {subprocess.py:93} INFO - 23/05/29 11:20:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:21:02.464+0000] {subprocess.py:93} INFO - 23/05/29 11:21:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:21:15.982+0000] {subprocess.py:93} INFO - 23/05/29 11:21:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:21:26.057+0000] {subprocess.py:93} INFO - 23/05/29 11:21:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:21:32.142+0000] {subprocess.py:93} INFO - 23/05/29 11:21:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:21:34.392+0000] {subprocess.py:93} INFO - 23/05/29 11:21:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:21:44.553+0000] {subprocess.py:93} INFO - 23/05/29 11:21:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:22:14.390+0000] {subprocess.py:93} INFO - 23/05/29 11:22:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:22:21.493+0000] {subprocess.py:93} INFO - 23/05/29 11:22:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:22:29.832+0000] {subprocess.py:93} INFO - 23/05/29 11:22:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:22:41.750+0000] {subprocess.py:93} INFO - 23/05/29 11:22:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:22:48.378+0000] {subprocess.py:93} INFO - 23/05/29 11:22:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:22:51.756+0000] {subprocess.py:93} INFO - 23/05/29 11:22:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:23:01.018+0000] {subprocess.py:93} INFO - 23/05/29 11:23:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:23:06.546+0000] {subprocess.py:93} INFO - 23/05/29 11:23:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:23:21.355+0000] {subprocess.py:93} INFO - 23/05/29 11:23:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:23:33.418+0000] {subprocess.py:93} INFO - 23/05/29 11:23:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:23:55.919+0000] {subprocess.py:93} INFO - 23/05/29 11:23:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:24:01.906+0000] {subprocess.py:93} INFO - 23/05/29 11:24:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:24:19.361+0000] {subprocess.py:93} INFO - 23/05/29 11:24:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:24:23.122+0000] {subprocess.py:93} INFO - 23/05/29 11:24:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:24:36.891+0000] {subprocess.py:93} INFO - 23/05/29 11:24:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:24:44.802+0000] {subprocess.py:93} INFO - 23/05/29 11:24:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:24:49.845+0000] {subprocess.py:93} INFO - 23/05/29 11:24:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:24:58.723+0000] {subprocess.py:93} INFO - 23/05/29 11:24:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:25:12.003+0000] {subprocess.py:93} INFO - 23/05/29 11:25:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:25:19.124+0000] {subprocess.py:93} INFO - 23/05/29 11:25:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:25:22.720+0000] {subprocess.py:93} INFO - 23/05/29 11:25:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:25:40.312+0000] {subprocess.py:93} INFO - 23/05/29 11:25:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:25:55.289+0000] {subprocess.py:93} INFO - 23/05/29 11:25:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:26:05.837+0000] {subprocess.py:93} INFO - 23/05/29 11:26:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:26:26.558+0000] {subprocess.py:93} INFO - 23/05/29 11:26:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:26:29.367+0000] {subprocess.py:93} INFO - 23/05/29 11:26:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:26:43.933+0000] {subprocess.py:93} INFO - 23/05/29 11:26:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:26:47.357+0000] {subprocess.py:93} INFO - 23/05/29 11:26:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:26:50.324+0000] {subprocess.py:93} INFO - 23/05/29 11:26:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:26:58.564+0000] {subprocess.py:93} INFO - 23/05/29 11:26:58 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:27:12.157+0000] {subprocess.py:93} INFO - 23/05/29 11:27:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:27:23.449+0000] {subprocess.py:93} INFO - 23/05/29 11:27:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:27:40.484+0000] {subprocess.py:93} INFO - 23/05/29 11:27:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:27:41.047+0000] {subprocess.py:93} INFO - 23/05/29 11:27:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:28:12.244+0000] {subprocess.py:93} INFO - 23/05/29 11:28:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:28:14.971+0000] {subprocess.py:93} INFO - 23/05/29 11:28:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:28:20.479+0000] {subprocess.py:93} INFO - 23/05/29 11:28:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:28:33.201+0000] {subprocess.py:93} INFO - 23/05/29 11:28:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:28:35.763+0000] {subprocess.py:93} INFO - 23/05/29 11:28:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:29:20.339+0000] {subprocess.py:93} INFO - 23/05/29 11:29:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:29:21.203+0000] {subprocess.py:93} INFO - 23/05/29 11:29:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:29:37.606+0000] {subprocess.py:93} INFO - 23/05/29 11:29:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:29:47.843+0000] {subprocess.py:93} INFO - 23/05/29 11:29:47 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:29:59.369+0000] {subprocess.py:93} INFO - 23/05/29 11:29:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:30:27.444+0000] {subprocess.py:93} INFO - 23/05/29 11:30:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:30:30.984+0000] {subprocess.py:93} INFO - 23/05/29 11:30:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:30:51.947+0000] {subprocess.py:93} INFO - 23/05/29 11:30:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:31:04.339+0000] {subprocess.py:93} INFO - 23/05/29 11:31:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:31:06.019+0000] {subprocess.py:93} INFO - 23/05/29 11:31:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:31:38.830+0000] {subprocess.py:93} INFO - 23/05/29 11:31:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:31:40.907+0000] {subprocess.py:93} INFO - 23/05/29 11:31:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:32:01.382+0000] {subprocess.py:93} INFO - 23/05/29 11:32:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:32:14.424+0000] {subprocess.py:93} INFO - 23/05/29 11:32:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:32:18.571+0000] {subprocess.py:93} INFO - 23/05/29 11:32:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:32:26.584+0000] {subprocess.py:93} INFO - 23/05/29 11:32:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:32:42.991+0000] {subprocess.py:93} INFO - 23/05/29 11:32:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:32:51.933+0000] {subprocess.py:93} INFO - 23/05/29 11:32:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:33:00.575+0000] {subprocess.py:93} INFO - 23/05/29 11:33:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:33:07.221+0000] {subprocess.py:93} INFO - 23/05/29 11:33:07 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:33:19.873+0000] {subprocess.py:93} INFO - 23/05/29 11:33:19 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:33:38.333+0000] {subprocess.py:93} INFO - 23/05/29 11:33:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:33:43.776+0000] {subprocess.py:93} INFO - 23/05/29 11:33:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:34:05.454+0000] {subprocess.py:93} INFO - 23/05/29 11:34:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:34:12.658+0000] {subprocess.py:93} INFO - 23/05/29 11:34:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:34:26.825+0000] {subprocess.py:93} INFO - 23/05/29 11:34:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:34:27.066+0000] {subprocess.py:93} INFO - 23/05/29 11:34:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:34:36.502+0000] {subprocess.py:93} INFO - 23/05/29 11:34:36 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:34:39.294+0000] {subprocess.py:93} INFO - 23/05/29 11:34:39 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:34:52.415+0000] {subprocess.py:93} INFO - 23/05/29 11:34:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:34:57.792+0000] {subprocess.py:93} INFO - 23/05/29 11:34:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:35:12.821+0000] {subprocess.py:93} INFO - 23/05/29 11:35:12 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:35:14.194+0000] {subprocess.py:93} INFO - 23/05/29 11:35:14 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:35:54.179+0000] {subprocess.py:93} INFO - 23/05/29 11:35:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:36:01.784+0000] {subprocess.py:93} INFO - 23/05/29 11:36:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:36:04.196+0000] {subprocess.py:93} INFO - 23/05/29 11:36:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:36:18.361+0000] {subprocess.py:93} INFO - 23/05/29 11:36:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:36:22.504+0000] {subprocess.py:93} INFO - 23/05/29 11:36:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:36:30.744+0000] {subprocess.py:93} INFO - 23/05/29 11:36:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:36:32.916+0000] {subprocess.py:93} INFO - 23/05/29 11:36:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:36:41.065+0000] {subprocess.py:93} INFO - 23/05/29 11:36:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:36:44.279+0000] {subprocess.py:93} INFO - 23/05/29 11:36:44 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:36:54.514+0000] {subprocess.py:93} INFO - 23/05/29 11:36:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:37:05.482+0000] {subprocess.py:93} INFO - 23/05/29 11:37:05 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:37:13.396+0000] {subprocess.py:93} INFO - 23/05/29 11:37:13 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:37:15.633+0000] {subprocess.py:93} INFO - 23/05/29 11:37:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:37:23.721+0000] {subprocess.py:93} INFO - 23/05/29 11:37:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:37:40.677+0000] {subprocess.py:93} INFO - 23/05/29 11:37:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:37:45.955+0000] {subprocess.py:93} INFO - 23/05/29 11:37:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:37:54.747+0000] {subprocess.py:93} INFO - 23/05/29 11:37:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:38:10.045+0000] {subprocess.py:93} INFO - 23/05/29 11:38:10 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:38:21.004+0000] {subprocess.py:93} INFO - 23/05/29 11:38:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:38:49.560+0000] {subprocess.py:93} INFO - 23/05/29 11:38:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:39:00.767+0000] {subprocess.py:93} INFO - 23/05/29 11:39:00 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:39:01.008+0000] {subprocess.py:93} INFO - 23/05/29 11:39:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:39:11.638+0000] {subprocess.py:93} INFO - 23/05/29 11:39:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:39:21.952+0000] {subprocess.py:93} INFO - 23/05/29 11:39:21 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:39:35.548+0000] {subprocess.py:93} INFO - 23/05/29 11:39:35 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:39:45.638+0000] {subprocess.py:93} INFO - 23/05/29 11:39:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:39:49.489+0000] {subprocess.py:93} INFO - 23/05/29 11:39:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:39:54.530+0000] {subprocess.py:93} INFO - 23/05/29 11:39:54 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:39:57.707+0000] {subprocess.py:93} INFO - 23/05/29 11:39:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:40:04.840+0000] {subprocess.py:93} INFO - 23/05/29 11:40:04 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:40:09.967+0000] {subprocess.py:93} INFO - 23/05/29 11:40:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:40:18.687+0000] {subprocess.py:93} INFO - 23/05/29 11:40:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:40:18.769+0000] {subprocess.py:93} INFO - 23/05/29 11:40:18 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:40:26.686+0000] {subprocess.py:93} INFO - 23/05/29 11:40:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:40:32.761+0000] {subprocess.py:93} INFO - 23/05/29 11:40:32 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:40:45.158+0000] {subprocess.py:93} INFO - 23/05/29 11:40:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:40:56.284+0000] {subprocess.py:93} INFO - 23/05/29 11:40:56 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:40:57.728+0000] {subprocess.py:93} INFO - 23/05/29 11:40:57 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:41:09.397+0000] {subprocess.py:93} INFO - 23/05/29 11:41:09 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:41:33.479+0000] {subprocess.py:93} INFO - 23/05/29 11:41:33 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:41:41.239+0000] {subprocess.py:93} INFO - 23/05/29 11:41:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:41:51.484+0000] {subprocess.py:93} INFO - 23/05/29 11:41:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:42:02.595+0000] {subprocess.py:93} INFO - 23/05/29 11:42:02 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:42:06.855+0000] {subprocess.py:93} INFO - 23/05/29 11:42:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:42:20.039+0000] {subprocess.py:93} INFO - 23/05/29 11:42:20 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:42:23.735+0000] {subprocess.py:93} INFO - 23/05/29 11:42:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:42:31.636+0000] {subprocess.py:93} INFO - 23/05/29 11:42:31 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:43:01.258+0000] {subprocess.py:93} INFO - 23/05/29 11:43:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:43:01.394+0000] {subprocess.py:93} INFO - 23/05/29 11:43:01 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:43:06.926+0000] {subprocess.py:93} INFO - 23/05/29 11:43:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:43:11.646+0000] {subprocess.py:93} INFO - 23/05/29 11:43:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:43:29.564+0000] {subprocess.py:93} INFO - 23/05/29 11:43:29 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:43:37.726+0000] {subprocess.py:93} INFO - 23/05/29 11:43:37 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:43:45.002+0000] {subprocess.py:93} INFO - 23/05/29 11:43:45 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:43:49.481+0000] {subprocess.py:93} INFO - 23/05/29 11:43:49 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:44:16.300+0000] {subprocess.py:93} INFO - 23/05/29 11:44:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:44:27.240+0000] {subprocess.py:93} INFO - 23/05/29 11:44:27 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:44:30.198+0000] {subprocess.py:93} INFO - 23/05/29 11:44:30 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:44:42.695+0000] {subprocess.py:93} INFO - 23/05/29 11:44:42 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:44:55.818+0000] {subprocess.py:93} INFO - 23/05/29 11:44:55 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:45:03.342+0000] {subprocess.py:93} INFO - 23/05/29 11:45:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:45:06.941+0000] {subprocess.py:93} INFO - 23/05/29 11:45:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:45:11.811+0000] {subprocess.py:93} INFO - 23/05/29 11:45:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:45:38.681+0000] {subprocess.py:93} INFO - 23/05/29 11:45:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:45:51.974+0000] {subprocess.py:93} INFO - 23/05/29 11:45:51 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:46:26.702+0000] {subprocess.py:93} INFO - 23/05/29 11:46:26 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:46:34.055+0000] {subprocess.py:93} INFO - 23/05/29 11:46:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:46:38.535+0000] {subprocess.py:93} INFO - 23/05/29 11:46:38 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:46:52.626+0000] {subprocess.py:93} INFO - 23/05/29 11:46:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:47:06.619+0000] {subprocess.py:93} INFO - 23/05/29 11:47:06 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:47:16.300+0000] {subprocess.py:93} INFO - 23/05/29 11:47:16 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:47:40.388+0000] {subprocess.py:93} INFO - 23/05/29 11:47:40 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:47:48.694+0000] {subprocess.py:93} INFO - 23/05/29 11:47:48 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:47:59.344+0000] {subprocess.py:93} INFO - 23/05/29 11:47:59 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:48:11.569+0000] {subprocess.py:93} INFO - 23/05/29 11:48:11 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:48:22.615+0000] {subprocess.py:93} INFO - 23/05/29 11:48:22 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:48:34.784+0000] {subprocess.py:93} INFO - 23/05/29 11:48:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:49:15.255+0000] {subprocess.py:93} INFO - 23/05/29 11:49:15 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:49:21.413+0000] {subprocess.py:93} INFO - 23/05/29 11:49:21 INFO MemoryStore: Block rdd_11_2 stored as values in memory (estimated size 44.7 MiB, free 281.7 MiB)
[2023-05-29T11:49:21.414+0000] {subprocess.py:93} INFO - 23/05/29 11:49:21 INFO BlockManagerInfo: Added rdd_11_2 in memory on 4b5d28de6f1c.mylabserver.com:39921 (size: 44.7 MiB, free: 336.8 MiB)
[2023-05-29T11:49:23.410+0000] {subprocess.py:93} INFO - 23/05/29 11:49:23 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:49:23.415+0000] {subprocess.py:93} INFO - 23/05/29 11:49:23 INFO UnsafeExternalSorter: Thread 73 spilling sort data of 120.0 MiB to disk (0  time so far)
[2023-05-29T11:49:34.870+0000] {subprocess.py:93} INFO - 23/05/29 11:49:34 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:49:38.936+0000] {subprocess.py:93} INFO - 23/05/29 11:49:38 INFO Executor: Finished task 2.0 in stage 2.0 (TID 5). 5290 bytes result sent to driver
[2023-05-29T11:49:38.939+0000] {subprocess.py:93} INFO - 23/05/29 11:49:38 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 5) in 2182666 ms on 4b5d28de6f1c.mylabserver.com (executor driver) (3/4)
[2023-05-29T11:49:41.584+0000] {subprocess.py:93} INFO - 23/05/29 11:49:41 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:49:43.348+0000] {subprocess.py:93} INFO - 23/05/29 11:49:43 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:49:50.137+0000] {subprocess.py:93} INFO - 23/05/29 11:49:50 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:49:52.787+0000] {subprocess.py:93} INFO - 23/05/29 11:49:52 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:50:03.839+0000] {subprocess.py:93} INFO - 23/05/29 11:50:03 INFO ExternalAppendOnlyUnsafeRowArray: Reached spill threshold of 4096 rows, switching to org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter
[2023-05-29T11:50:08.382+0000] {subprocess.py:93} INFO - 23/05/29 11:50:08 INFO MemoryStore: Block rdd_11_3 stored as values in memory (estimated size 42.7 MiB, free 247.1 MiB)
[2023-05-29T11:50:08.382+0000] {subprocess.py:93} INFO - 23/05/29 11:50:08 INFO BlockManagerInfo: Added rdd_11_3 in memory on 4b5d28de6f1c.mylabserver.com:39921 (size: 42.7 MiB, free: 294.1 MiB)
[2023-05-29T11:50:12.612+0000] {subprocess.py:93} INFO - 23/05/29 11:50:12 INFO Executor: Finished task 3.0 in stage 2.0 (TID 6). 5290 bytes result sent to driver
[2023-05-29T11:50:12.614+0000] {subprocess.py:93} INFO - 23/05/29 11:50:12 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 6) in 1921201 ms on 4b5d28de6f1c.mylabserver.com (executor driver) (4/4)
[2023-05-29T11:50:12.615+0000] {subprocess.py:93} INFO - 23/05/29 11:50:12 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2023-05-29T11:50:12.617+0000] {subprocess.py:93} INFO - 23/05/29 11:50:12 INFO DAGScheduler: ShuffleMapStage 2 (parquet at NativeMethodAccessorImpl.java:0) finished in 4645.948 s
[2023-05-29T11:50:12.617+0000] {subprocess.py:93} INFO - 23/05/29 11:50:12 INFO DAGScheduler: looking for newly runnable stages
[2023-05-29T11:50:12.617+0000] {subprocess.py:93} INFO - 23/05/29 11:50:12 INFO DAGScheduler: running: Set()
[2023-05-29T11:50:12.617+0000] {subprocess.py:93} INFO - 23/05/29 11:50:12 INFO DAGScheduler: waiting: Set()
[2023-05-29T11:50:12.617+0000] {subprocess.py:93} INFO - 23/05/29 11:50:12 INFO DAGScheduler: failed: Set()
[2023-05-29T11:50:12.869+0000] {subprocess.py:93} INFO - 23/05/29 11:50:12 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-29T11:50:12.943+0000] {subprocess.py:93} INFO - 23/05/29 11:50:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-29T11:50:12.943+0000] {subprocess.py:93} INFO - 23/05/29 11:50:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-29T11:50:12.943+0000] {subprocess.py:93} INFO - 23/05/29 11:50:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-29T11:50:12.944+0000] {subprocess.py:93} INFO - 23/05/29 11:50:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-29T11:50:12.944+0000] {subprocess.py:93} INFO - 23/05/29 11:50:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-29T11:50:12.944+0000] {subprocess.py:93} INFO - 23/05/29 11:50:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-29T11:50:13.028+0000] {subprocess.py:93} INFO - 23/05/29 11:50:13 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
[2023-05-29T11:50:13.031+0000] {subprocess.py:93} INFO - 23/05/29 11:50:13 INFO DAGScheduler: Got job 2 (parquet at NativeMethodAccessorImpl.java:0) with 10 output partitions
[2023-05-29T11:50:13.031+0000] {subprocess.py:93} INFO - 23/05/29 11:50:13 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
[2023-05-29T11:50:13.031+0000] {subprocess.py:93} INFO - 23/05/29 11:50:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
[2023-05-29T11:50:13.031+0000] {subprocess.py:93} INFO - 23/05/29 11:50:13 INFO DAGScheduler: Missing parents: List()
[2023-05-29T11:50:13.093+0000] {subprocess.py:93} INFO - 23/05/29 11:50:13 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[18] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
[2023-05-29T11:50:13.418+0000] {subprocess.py:93} INFO - 23/05/29 11:50:13 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 212.2 KiB, free 246.9 MiB)
[2023-05-29T11:50:13.421+0000] {subprocess.py:93} INFO - 23/05/29 11:50:13 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 76.3 KiB, free 246.8 MiB)
[2023-05-29T11:50:13.422+0000] {subprocess.py:93} INFO - 23/05/29 11:50:13 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 4b5d28de6f1c.mylabserver.com:39921 (size: 76.3 KiB, free: 294.0 MiB)
[2023-05-29T11:50:13.423+0000] {subprocess.py:93} INFO - 23/05/29 11:50:13 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1535
[2023-05-29T11:50:13.434+0000] {subprocess.py:93} INFO - 23/05/29 11:50:13 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 5 (MapPartitionsRDD[18] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2023-05-29T11:50:13.435+0000] {subprocess.py:93} INFO - 23/05/29 11:50:13 INFO TaskSchedulerImpl: Adding task set 5.0 with 10 tasks resource profile 0
[2023-05-29T11:50:13.513+0000] {subprocess.py:93} INFO - 23/05/29 11:50:13 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 7) (4b5d28de6f1c.mylabserver.com, executor driver, partition 0, NODE_LOCAL, 7363 bytes)
[2023-05-29T11:50:13.514+0000] {subprocess.py:93} INFO - 23/05/29 11:50:13 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 8) (4b5d28de6f1c.mylabserver.com, executor driver, partition 1, NODE_LOCAL, 7363 bytes)
[2023-05-29T11:50:13.577+0000] {subprocess.py:93} INFO - 23/05/29 11:50:13 INFO Executor: Running task 1.0 in stage 5.0 (TID 8)
[2023-05-29T11:50:13.581+0000] {subprocess.py:93} INFO - 23/05/29 11:50:13 INFO Executor: Running task 0.0 in stage 5.0 (TID 7)
[2023-05-29T11:50:13.978+0000] {subprocess.py:93} INFO - 23/05/29 11:50:13 INFO ShuffleBlockFetcherIterator: Getting 4 (32.8 MiB) non-empty blocks including 4 (32.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-05-29T11:50:13.978+0000] {subprocess.py:93} INFO - 23/05/29 11:50:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2023-05-29T11:50:13.980+0000] {subprocess.py:93} INFO - 23/05/29 11:50:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-29T11:50:13.980+0000] {subprocess.py:93} INFO - 23/05/29 11:50:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-29T11:50:13.981+0000] {subprocess.py:93} INFO - 23/05/29 11:50:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-29T11:50:13.981+0000] {subprocess.py:93} INFO - 23/05/29 11:50:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-29T11:50:13.981+0000] {subprocess.py:93} INFO - 23/05/29 11:50:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-29T11:50:13.981+0000] {subprocess.py:93} INFO - 23/05/29 11:50:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-29T11:50:13.986+0000] {subprocess.py:93} INFO - 23/05/29 11:50:13 INFO CodecConfig: Compression: SNAPPY
[2023-05-29T11:50:13.989+0000] {subprocess.py:93} INFO - 23/05/29 11:50:13 INFO CodecConfig: Compression: SNAPPY
[2023-05-29T11:50:14.057+0000] {subprocess.py:93} INFO - 23/05/29 11:50:14 INFO ShuffleBlockFetcherIterator: Getting 4 (32.8 MiB) non-empty blocks including 4 (32.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-05-29T11:50:14.058+0000] {subprocess.py:93} INFO - 23/05/29 11:50:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2023-05-29T11:50:14.058+0000] {subprocess.py:93} INFO - 23/05/29 11:50:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-29T11:50:14.058+0000] {subprocess.py:93} INFO - 23/05/29 11:50:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-29T11:50:14.058+0000] {subprocess.py:93} INFO - 23/05/29 11:50:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-29T11:50:14.058+0000] {subprocess.py:93} INFO - 23/05/29 11:50:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-29T11:50:14.058+0000] {subprocess.py:93} INFO - 23/05/29 11:50:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-29T11:50:14.059+0000] {subprocess.py:93} INFO - 23/05/29 11:50:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-29T11:50:14.059+0000] {subprocess.py:93} INFO - 23/05/29 11:50:14 INFO CodecConfig: Compression: SNAPPY
[2023-05-29T11:50:14.060+0000] {subprocess.py:93} INFO - 23/05/29 11:50:14 INFO CodecConfig: Compression: SNAPPY
[2023-05-29T11:50:14.136+0000] {subprocess.py:93} INFO - 23/05/29 11:50:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2023-05-29T11:50:14.147+0000] {subprocess.py:93} INFO - 23/05/29 11:50:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2023-05-29T11:50:14.147+0000] {subprocess.py:93} INFO - {
[2023-05-29T11:50:14.147+0000] {subprocess.py:93} INFO -   "type" : "struct",
[2023-05-29T11:50:14.147+0000] {subprocess.py:93} INFO -   "fields" : [ {
[2023-05-29T11:50:14.148+0000] {subprocess.py:93} INFO -     "name" : "Date",
[2023-05-29T11:50:14.148+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:50:14.148+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:14.148+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:14.148+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:14.148+0000] {subprocess.py:93} INFO -     "name" : "Open",
[2023-05-29T11:50:14.149+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:14.149+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:14.149+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:14.149+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:14.149+0000] {subprocess.py:93} INFO -     "name" : "High",
[2023-05-29T11:50:14.149+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:14.149+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:14.150+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:14.150+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:14.150+0000] {subprocess.py:93} INFO -     "name" : "Low",
[2023-05-29T11:50:14.150+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:14.150+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:14.150+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:14.150+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:14.150+0000] {subprocess.py:93} INFO -     "name" : "Close",
[2023-05-29T11:50:14.151+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:14.151+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:14.151+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:14.151+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:14.151+0000] {subprocess.py:93} INFO -     "name" : "Adj_Close",
[2023-05-29T11:50:14.151+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:14.151+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:14.152+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:14.152+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:14.152+0000] {subprocess.py:93} INFO -     "name" : "Volume",
[2023-05-29T11:50:14.152+0000] {subprocess.py:93} INFO -     "type" : "integer",
[2023-05-29T11:50:14.152+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:14.152+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:14.152+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:14.153+0000] {subprocess.py:93} INFO -     "name" : "Symbol",
[2023-05-29T11:50:14.153+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:50:14.212+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:14.212+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:14.212+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:14.212+0000] {subprocess.py:93} INFO -     "name" : "Security_Name",
[2023-05-29T11:50:14.213+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:50:14.213+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:14.213+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:14.213+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:14.213+0000] {subprocess.py:93} INFO -     "name" : "vol_moving_avg",
[2023-05-29T11:50:14.213+0000] {subprocess.py:93} INFO -     "type" : "double",
[2023-05-29T11:50:14.213+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:14.213+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:14.214+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:14.214+0000] {subprocess.py:93} INFO -     "name" : "adj_close_rolling_med",
[2023-05-29T11:50:14.214+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:14.214+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:14.214+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:14.214+0000] {subprocess.py:93} INFO -   } ]
[2023-05-29T11:50:14.214+0000] {subprocess.py:93} INFO - }
[2023-05-29T11:50:14.214+0000] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2023-05-29T11:50:14.215+0000] {subprocess.py:93} INFO - message spark_schema {
[2023-05-29T11:50:14.215+0000] {subprocess.py:93} INFO -   optional binary Date (STRING);
[2023-05-29T11:50:14.215+0000] {subprocess.py:93} INFO -   optional float Open;
[2023-05-29T11:50:14.215+0000] {subprocess.py:93} INFO -   optional float High;
[2023-05-29T11:50:14.215+0000] {subprocess.py:93} INFO -   optional float Low;
[2023-05-29T11:50:14.215+0000] {subprocess.py:93} INFO -   optional float Close;
[2023-05-29T11:50:14.215+0000] {subprocess.py:93} INFO -   optional float Adj_Close;
[2023-05-29T11:50:14.215+0000] {subprocess.py:93} INFO -   optional int32 Volume;
[2023-05-29T11:50:14.215+0000] {subprocess.py:93} INFO -   optional binary Symbol (STRING);
[2023-05-29T11:50:14.216+0000] {subprocess.py:93} INFO -   optional binary Security_Name (STRING);
[2023-05-29T11:50:14.216+0000] {subprocess.py:93} INFO -   optional double vol_moving_avg;
[2023-05-29T11:50:14.216+0000] {subprocess.py:93} INFO -   optional float adj_close_rolling_med;
[2023-05-29T11:50:14.216+0000] {subprocess.py:93} INFO - }
[2023-05-29T11:50:14.216+0000] {subprocess.py:93} INFO - 
[2023-05-29T11:50:14.216+0000] {subprocess.py:93} INFO - 
[2023-05-29T11:50:14.216+0000] {subprocess.py:93} INFO - 23/05/29 11:50:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2023-05-29T11:50:14.216+0000] {subprocess.py:93} INFO - 23/05/29 11:50:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2023-05-29T11:50:14.217+0000] {subprocess.py:93} INFO - {
[2023-05-29T11:50:14.217+0000] {subprocess.py:93} INFO -   "type" : "struct",
[2023-05-29T11:50:14.220+0000] {subprocess.py:93} INFO -   "fields" : [ {
[2023-05-29T11:50:14.220+0000] {subprocess.py:93} INFO -     "name" : "Date",
[2023-05-29T11:50:14.221+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:50:14.221+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:14.221+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:14.221+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:14.221+0000] {subprocess.py:93} INFO -     "name" : "Open",
[2023-05-29T11:50:14.221+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:14.222+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:14.222+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:14.222+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:14.222+0000] {subprocess.py:93} INFO -     "name" : "High",
[2023-05-29T11:50:14.222+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:14.222+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:14.222+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:14.222+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:14.222+0000] {subprocess.py:93} INFO -     "name" : "Low",
[2023-05-29T11:50:14.223+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:14.223+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:14.223+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:14.223+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:14.223+0000] {subprocess.py:93} INFO -     "name" : "Close",
[2023-05-29T11:50:14.223+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:14.223+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:14.223+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:14.223+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:14.224+0000] {subprocess.py:93} INFO -     "name" : "Adj_Close",
[2023-05-29T11:50:14.224+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:14.224+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:14.227+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:14.227+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:14.227+0000] {subprocess.py:93} INFO -     "name" : "Volume",
[2023-05-29T11:50:14.227+0000] {subprocess.py:93} INFO -     "type" : "integer",
[2023-05-29T11:50:14.227+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:14.227+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:14.228+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:14.228+0000] {subprocess.py:93} INFO -     "name" : "Symbol",
[2023-05-29T11:50:14.228+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:50:14.228+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:14.228+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:14.228+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:14.228+0000] {subprocess.py:93} INFO -     "name" : "Security_Name",
[2023-05-29T11:50:14.228+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:50:14.229+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:14.229+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:14.229+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:14.229+0000] {subprocess.py:93} INFO -     "name" : "vol_moving_avg",
[2023-05-29T11:50:14.229+0000] {subprocess.py:93} INFO -     "type" : "double",
[2023-05-29T11:50:14.229+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:14.229+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:14.229+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:14.229+0000] {subprocess.py:93} INFO -     "name" : "adj_close_rolling_med",
[2023-05-29T11:50:14.230+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:14.230+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:14.230+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:14.230+0000] {subprocess.py:93} INFO -   } ]
[2023-05-29T11:50:14.230+0000] {subprocess.py:93} INFO - }
[2023-05-29T11:50:14.230+0000] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2023-05-29T11:50:14.230+0000] {subprocess.py:93} INFO - message spark_schema {
[2023-05-29T11:50:14.230+0000] {subprocess.py:93} INFO -   optional binary Date (STRING);
[2023-05-29T11:50:14.231+0000] {subprocess.py:93} INFO -   optional float Open;
[2023-05-29T11:50:14.231+0000] {subprocess.py:93} INFO -   optional float High;
[2023-05-29T11:50:14.231+0000] {subprocess.py:93} INFO -   optional float Low;
[2023-05-29T11:50:14.231+0000] {subprocess.py:93} INFO -   optional float Close;
[2023-05-29T11:50:14.231+0000] {subprocess.py:93} INFO -   optional float Adj_Close;
[2023-05-29T11:50:14.231+0000] {subprocess.py:93} INFO -   optional int32 Volume;
[2023-05-29T11:50:14.231+0000] {subprocess.py:93} INFO -   optional binary Symbol (STRING);
[2023-05-29T11:50:14.231+0000] {subprocess.py:93} INFO -   optional binary Security_Name (STRING);
[2023-05-29T11:50:14.231+0000] {subprocess.py:93} INFO -   optional double vol_moving_avg;
[2023-05-29T11:50:14.232+0000] {subprocess.py:93} INFO -   optional float adj_close_rolling_med;
[2023-05-29T11:50:14.232+0000] {subprocess.py:93} INFO - }
[2023-05-29T11:50:14.232+0000] {subprocess.py:93} INFO - 
[2023-05-29T11:50:14.232+0000] {subprocess.py:93} INFO - 
[2023-05-29T11:50:14.303+0000] {subprocess.py:93} INFO - 23/05/29 11:50:14 INFO CodecPool: Got brand-new compressor [.snappy]
[2023-05-29T11:50:14.303+0000] {subprocess.py:93} INFO - 23/05/29 11:50:14 INFO CodecPool: Got brand-new compressor [.snappy]
[2023-05-29T11:50:34.947+0000] {subprocess.py:93} INFO - 23/05/29 11:50:34 INFO FileOutputCommitter: Saved output of task 'attempt_202305291150134401829585508501164_0005_m_000001_8' to file:/home/cloud_user/Stock-Market-Nasdaq/data/processed_data/parquet_format_avg_med/stocks.parquet/_temporary/0/task_202305291150134401829585508501164_0005_m_000001
[2023-05-29T11:50:34.948+0000] {subprocess.py:93} INFO - 23/05/29 11:50:34 INFO SparkHadoopMapRedUtil: attempt_202305291150134401829585508501164_0005_m_000001_8: Committed. Elapsed time: 1 ms.
[2023-05-29T11:50:35.100+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO Executor: Finished task 1.0 in stage 5.0 (TID 8). 4826 bytes result sent to driver
[2023-05-29T11:50:35.101+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 9) (4b5d28de6f1c.mylabserver.com, executor driver, partition 2, NODE_LOCAL, 7363 bytes)
[2023-05-29T11:50:35.103+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 8) in 21588 ms on 4b5d28de6f1c.mylabserver.com (executor driver) (1/10)
[2023-05-29T11:50:35.109+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO Executor: Running task 2.0 in stage 5.0 (TID 9)
[2023-05-29T11:50:35.273+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO ShuffleBlockFetcherIterator: Getting 4 (32.8 MiB) non-empty blocks including 4 (32.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-05-29T11:50:35.273+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2023-05-29T11:50:35.276+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-29T11:50:35.333+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-29T11:50:35.334+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-29T11:50:35.334+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-29T11:50:35.334+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-29T11:50:35.335+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-29T11:50:35.335+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO CodecConfig: Compression: SNAPPY
[2023-05-29T11:50:35.336+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO CodecConfig: Compression: SNAPPY
[2023-05-29T11:50:35.338+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2023-05-29T11:50:35.349+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2023-05-29T11:50:35.349+0000] {subprocess.py:93} INFO - {
[2023-05-29T11:50:35.350+0000] {subprocess.py:93} INFO -   "type" : "struct",
[2023-05-29T11:50:35.350+0000] {subprocess.py:93} INFO -   "fields" : [ {
[2023-05-29T11:50:35.350+0000] {subprocess.py:93} INFO -     "name" : "Date",
[2023-05-29T11:50:35.350+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:50:35.350+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:35.350+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:35.350+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:35.350+0000] {subprocess.py:93} INFO -     "name" : "Open",
[2023-05-29T11:50:35.350+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:35.350+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:35.350+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:35.351+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:35.351+0000] {subprocess.py:93} INFO -     "name" : "High",
[2023-05-29T11:50:35.351+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:35.351+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:35.351+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:35.351+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:35.351+0000] {subprocess.py:93} INFO -     "name" : "Low",
[2023-05-29T11:50:35.351+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:35.351+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:35.351+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:35.351+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:35.351+0000] {subprocess.py:93} INFO -     "name" : "Close",
[2023-05-29T11:50:35.351+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:35.352+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:35.352+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:35.352+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:35.352+0000] {subprocess.py:93} INFO -     "name" : "Adj_Close",
[2023-05-29T11:50:35.352+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:35.352+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:35.352+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:35.352+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:35.352+0000] {subprocess.py:93} INFO -     "name" : "Volume",
[2023-05-29T11:50:35.352+0000] {subprocess.py:93} INFO -     "type" : "integer",
[2023-05-29T11:50:35.352+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:35.352+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:35.353+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:35.353+0000] {subprocess.py:93} INFO -     "name" : "Symbol",
[2023-05-29T11:50:35.353+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:50:35.353+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:35.353+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:35.354+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:35.354+0000] {subprocess.py:93} INFO -     "name" : "Security_Name",
[2023-05-29T11:50:35.354+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:50:35.354+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:35.354+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:35.354+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:35.354+0000] {subprocess.py:93} INFO -     "name" : "vol_moving_avg",
[2023-05-29T11:50:35.354+0000] {subprocess.py:93} INFO -     "type" : "double",
[2023-05-29T11:50:35.355+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:35.355+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:35.355+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:35.355+0000] {subprocess.py:93} INFO -     "name" : "adj_close_rolling_med",
[2023-05-29T11:50:35.355+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:35.355+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:35.355+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:35.355+0000] {subprocess.py:93} INFO -   } ]
[2023-05-29T11:50:35.356+0000] {subprocess.py:93} INFO - }
[2023-05-29T11:50:35.356+0000] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2023-05-29T11:50:35.356+0000] {subprocess.py:93} INFO - message spark_schema {
[2023-05-29T11:50:35.356+0000] {subprocess.py:93} INFO -   optional binary Date (STRING);
[2023-05-29T11:50:35.356+0000] {subprocess.py:93} INFO -   optional float Open;
[2023-05-29T11:50:35.356+0000] {subprocess.py:93} INFO -   optional float High;
[2023-05-29T11:50:35.356+0000] {subprocess.py:93} INFO -   optional float Low;
[2023-05-29T11:50:35.356+0000] {subprocess.py:93} INFO -   optional float Close;
[2023-05-29T11:50:35.357+0000] {subprocess.py:93} INFO -   optional float Adj_Close;
[2023-05-29T11:50:35.357+0000] {subprocess.py:93} INFO -   optional int32 Volume;
[2023-05-29T11:50:35.358+0000] {subprocess.py:93} INFO -   optional binary Symbol (STRING);
[2023-05-29T11:50:35.358+0000] {subprocess.py:93} INFO -   optional binary Security_Name (STRING);
[2023-05-29T11:50:35.358+0000] {subprocess.py:93} INFO -   optional double vol_moving_avg;
[2023-05-29T11:50:35.358+0000] {subprocess.py:93} INFO -   optional float adj_close_rolling_med;
[2023-05-29T11:50:35.358+0000] {subprocess.py:93} INFO - }
[2023-05-29T11:50:35.358+0000] {subprocess.py:93} INFO - 
[2023-05-29T11:50:35.358+0000] {subprocess.py:93} INFO - 
[2023-05-29T11:50:35.358+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO FileOutputCommitter: Saved output of task 'attempt_202305291150134401829585508501164_0005_m_000000_7' to file:/home/cloud_user/Stock-Market-Nasdaq/data/processed_data/parquet_format_avg_med/stocks.parquet/_temporary/0/task_202305291150134401829585508501164_0005_m_000000
[2023-05-29T11:50:35.358+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO SparkHadoopMapRedUtil: attempt_202305291150134401829585508501164_0005_m_000000_7: Committed. Elapsed time: 1 ms.
[2023-05-29T11:50:35.493+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO Executor: Finished task 0.0 in stage 5.0 (TID 7). 4783 bytes result sent to driver
[2023-05-29T11:50:35.495+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 10) (4b5d28de6f1c.mylabserver.com, executor driver, partition 3, NODE_LOCAL, 7363 bytes)
[2023-05-29T11:50:35.495+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 7) in 22003 ms on 4b5d28de6f1c.mylabserver.com (executor driver) (2/10)
[2023-05-29T11:50:35.495+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO Executor: Running task 3.0 in stage 5.0 (TID 10)
[2023-05-29T11:50:35.661+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO ShuffleBlockFetcherIterator: Getting 4 (32.8 MiB) non-empty blocks including 4 (32.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-05-29T11:50:35.661+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2023-05-29T11:50:35.663+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-29T11:50:35.663+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-29T11:50:35.664+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-29T11:50:35.664+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-29T11:50:35.664+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-29T11:50:35.666+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-29T11:50:35.666+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO CodecConfig: Compression: SNAPPY
[2023-05-29T11:50:35.673+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO CodecConfig: Compression: SNAPPY
[2023-05-29T11:50:35.676+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2023-05-29T11:50:35.823+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2023-05-29T11:50:35.823+0000] {subprocess.py:93} INFO - {
[2023-05-29T11:50:35.823+0000] {subprocess.py:93} INFO -   "type" : "struct",
[2023-05-29T11:50:35.823+0000] {subprocess.py:93} INFO -   "fields" : [ {
[2023-05-29T11:50:35.823+0000] {subprocess.py:93} INFO -     "name" : "Date",
[2023-05-29T11:50:35.824+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:50:35.824+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:35.824+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:35.824+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:35.824+0000] {subprocess.py:93} INFO -     "name" : "Open",
[2023-05-29T11:50:35.824+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:35.824+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:35.825+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:35.825+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:35.825+0000] {subprocess.py:93} INFO -     "name" : "High",
[2023-05-29T11:50:35.825+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:35.825+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:35.825+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:35.825+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:35.825+0000] {subprocess.py:93} INFO -     "name" : "Low",
[2023-05-29T11:50:35.826+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:35.826+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:35.826+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:35.826+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:35.826+0000] {subprocess.py:93} INFO -     "name" : "Close",
[2023-05-29T11:50:35.826+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:35.826+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:35.827+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:35.827+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:35.827+0000] {subprocess.py:93} INFO -     "name" : "Adj_Close",
[2023-05-29T11:50:35.827+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:35.827+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:35.827+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:35.827+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:35.827+0000] {subprocess.py:93} INFO -     "name" : "Volume",
[2023-05-29T11:50:35.828+0000] {subprocess.py:93} INFO -     "type" : "integer",
[2023-05-29T11:50:35.828+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:35.828+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:35.828+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:35.828+0000] {subprocess.py:93} INFO -     "name" : "Symbol",
[2023-05-29T11:50:35.828+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:50:35.828+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:35.828+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:35.829+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:35.829+0000] {subprocess.py:93} INFO -     "name" : "Security_Name",
[2023-05-29T11:50:35.829+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:50:35.829+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:35.829+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:35.829+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:35.830+0000] {subprocess.py:93} INFO -     "name" : "vol_moving_avg",
[2023-05-29T11:50:35.830+0000] {subprocess.py:93} INFO -     "type" : "double",
[2023-05-29T11:50:35.830+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:35.830+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:35.830+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:35.830+0000] {subprocess.py:93} INFO -     "name" : "adj_close_rolling_med",
[2023-05-29T11:50:35.830+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:35.830+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:35.830+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:35.831+0000] {subprocess.py:93} INFO -   } ]
[2023-05-29T11:50:35.831+0000] {subprocess.py:93} INFO - }
[2023-05-29T11:50:35.831+0000] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2023-05-29T11:50:35.831+0000] {subprocess.py:93} INFO - message spark_schema {
[2023-05-29T11:50:35.831+0000] {subprocess.py:93} INFO -   optional binary Date (STRING);
[2023-05-29T11:50:35.831+0000] {subprocess.py:93} INFO -   optional float Open;
[2023-05-29T11:50:35.831+0000] {subprocess.py:93} INFO -   optional float High;
[2023-05-29T11:50:35.831+0000] {subprocess.py:93} INFO -   optional float Low;
[2023-05-29T11:50:35.831+0000] {subprocess.py:93} INFO -   optional float Close;
[2023-05-29T11:50:35.831+0000] {subprocess.py:93} INFO -   optional float Adj_Close;
[2023-05-29T11:50:35.832+0000] {subprocess.py:93} INFO -   optional int32 Volume;
[2023-05-29T11:50:35.832+0000] {subprocess.py:93} INFO -   optional binary Symbol (STRING);
[2023-05-29T11:50:35.832+0000] {subprocess.py:93} INFO -   optional binary Security_Name (STRING);
[2023-05-29T11:50:35.832+0000] {subprocess.py:93} INFO -   optional double vol_moving_avg;
[2023-05-29T11:50:35.832+0000] {subprocess.py:93} INFO -   optional float adj_close_rolling_med;
[2023-05-29T11:50:35.832+0000] {subprocess.py:93} INFO - }
[2023-05-29T11:50:35.832+0000] {subprocess.py:93} INFO - 
[2023-05-29T11:50:35.832+0000] {subprocess.py:93} INFO - 
[2023-05-29T11:50:35.900+0000] {subprocess.py:93} INFO - 23/05/29 11:50:35 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 4b5d28de6f1c.mylabserver.com:39921 in memory (size: 21.9 KiB, free: 294.0 MiB)
[2023-05-29T11:50:48.697+0000] {subprocess.py:93} INFO - 23/05/29 11:50:48 INFO FileOutputCommitter: Saved output of task 'attempt_202305291150134401829585508501164_0005_m_000003_10' to file:/home/cloud_user/Stock-Market-Nasdaq/data/processed_data/parquet_format_avg_med/stocks.parquet/_temporary/0/task_202305291150134401829585508501164_0005_m_000003
[2023-05-29T11:50:48.698+0000] {subprocess.py:93} INFO - 23/05/29 11:50:48 INFO SparkHadoopMapRedUtil: attempt_202305291150134401829585508501164_0005_m_000003_10: Committed. Elapsed time: 1 ms.
[2023-05-29T11:50:48.699+0000] {subprocess.py:93} INFO - 23/05/29 11:50:48 INFO Executor: Finished task 3.0 in stage 5.0 (TID 10). 4783 bytes result sent to driver
[2023-05-29T11:50:48.701+0000] {subprocess.py:93} INFO - 23/05/29 11:50:48 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 11) (4b5d28de6f1c.mylabserver.com, executor driver, partition 4, NODE_LOCAL, 7363 bytes)
[2023-05-29T11:50:48.701+0000] {subprocess.py:93} INFO - 23/05/29 11:50:48 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 10) in 13207 ms on 4b5d28de6f1c.mylabserver.com (executor driver) (3/10)
[2023-05-29T11:50:48.702+0000] {subprocess.py:93} INFO - 23/05/29 11:50:48 INFO Executor: Running task 4.0 in stage 5.0 (TID 11)
[2023-05-29T11:50:48.782+0000] {subprocess.py:93} INFO - 23/05/29 11:50:48 INFO ShuffleBlockFetcherIterator: Getting 4 (32.8 MiB) non-empty blocks including 4 (32.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-05-29T11:50:48.783+0000] {subprocess.py:93} INFO - 23/05/29 11:50:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2023-05-29T11:50:48.786+0000] {subprocess.py:93} INFO - 23/05/29 11:50:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-29T11:50:48.786+0000] {subprocess.py:93} INFO - 23/05/29 11:50:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-29T11:50:48.786+0000] {subprocess.py:93} INFO - 23/05/29 11:50:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-29T11:50:48.787+0000] {subprocess.py:93} INFO - 23/05/29 11:50:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-29T11:50:48.787+0000] {subprocess.py:93} INFO - 23/05/29 11:50:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-29T11:50:48.787+0000] {subprocess.py:93} INFO - 23/05/29 11:50:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-29T11:50:48.787+0000] {subprocess.py:93} INFO - 23/05/29 11:50:48 INFO CodecConfig: Compression: SNAPPY
[2023-05-29T11:50:48.788+0000] {subprocess.py:93} INFO - 23/05/29 11:50:48 INFO CodecConfig: Compression: SNAPPY
[2023-05-29T11:50:48.791+0000] {subprocess.py:93} INFO - 23/05/29 11:50:48 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2023-05-29T11:50:48.860+0000] {subprocess.py:93} INFO - 23/05/29 11:50:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2023-05-29T11:50:48.861+0000] {subprocess.py:93} INFO - {
[2023-05-29T11:50:48.861+0000] {subprocess.py:93} INFO -   "type" : "struct",
[2023-05-29T11:50:48.861+0000] {subprocess.py:93} INFO -   "fields" : [ {
[2023-05-29T11:50:48.861+0000] {subprocess.py:93} INFO -     "name" : "Date",
[2023-05-29T11:50:48.861+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:50:48.861+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:48.861+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:48.862+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:48.862+0000] {subprocess.py:93} INFO -     "name" : "Open",
[2023-05-29T11:50:48.862+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:48.862+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:48.862+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:48.862+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:48.862+0000] {subprocess.py:93} INFO -     "name" : "High",
[2023-05-29T11:50:48.862+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:48.863+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:48.863+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:48.863+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:48.863+0000] {subprocess.py:93} INFO -     "name" : "Low",
[2023-05-29T11:50:48.863+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:48.863+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:48.863+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:48.863+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:48.863+0000] {subprocess.py:93} INFO -     "name" : "Close",
[2023-05-29T11:50:48.864+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:48.864+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:48.864+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:48.864+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:48.864+0000] {subprocess.py:93} INFO -     "name" : "Adj_Close",
[2023-05-29T11:50:48.864+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:48.864+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:48.864+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:48.864+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:48.865+0000] {subprocess.py:93} INFO -     "name" : "Volume",
[2023-05-29T11:50:48.865+0000] {subprocess.py:93} INFO -     "type" : "integer",
[2023-05-29T11:50:48.865+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:48.865+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:48.865+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:48.865+0000] {subprocess.py:93} INFO -     "name" : "Symbol",
[2023-05-29T11:50:48.865+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:50:48.865+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:48.866+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:48.866+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:48.866+0000] {subprocess.py:93} INFO -     "name" : "Security_Name",
[2023-05-29T11:50:48.866+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:50:48.866+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:48.866+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:48.866+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:48.866+0000] {subprocess.py:93} INFO -     "name" : "vol_moving_avg",
[2023-05-29T11:50:48.866+0000] {subprocess.py:93} INFO -     "type" : "double",
[2023-05-29T11:50:48.867+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:48.867+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:48.867+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:48.867+0000] {subprocess.py:93} INFO -     "name" : "adj_close_rolling_med",
[2023-05-29T11:50:48.867+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:48.867+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:48.867+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:48.867+0000] {subprocess.py:93} INFO -   } ]
[2023-05-29T11:50:48.867+0000] {subprocess.py:93} INFO - }
[2023-05-29T11:50:48.868+0000] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2023-05-29T11:50:48.868+0000] {subprocess.py:93} INFO - message spark_schema {
[2023-05-29T11:50:48.868+0000] {subprocess.py:93} INFO -   optional binary Date (STRING);
[2023-05-29T11:50:48.868+0000] {subprocess.py:93} INFO -   optional float Open;
[2023-05-29T11:50:48.868+0000] {subprocess.py:93} INFO -   optional float High;
[2023-05-29T11:50:48.868+0000] {subprocess.py:93} INFO -   optional float Low;
[2023-05-29T11:50:48.868+0000] {subprocess.py:93} INFO -   optional float Close;
[2023-05-29T11:50:48.868+0000] {subprocess.py:93} INFO -   optional float Adj_Close;
[2023-05-29T11:50:48.868+0000] {subprocess.py:93} INFO -   optional int32 Volume;
[2023-05-29T11:50:48.869+0000] {subprocess.py:93} INFO -   optional binary Symbol (STRING);
[2023-05-29T11:50:48.870+0000] {subprocess.py:93} INFO -   optional binary Security_Name (STRING);
[2023-05-29T11:50:48.870+0000] {subprocess.py:93} INFO -   optional double vol_moving_avg;
[2023-05-29T11:50:48.870+0000] {subprocess.py:93} INFO -   optional float adj_close_rolling_med;
[2023-05-29T11:50:48.870+0000] {subprocess.py:93} INFO - }
[2023-05-29T11:50:48.870+0000] {subprocess.py:93} INFO - 
[2023-05-29T11:50:48.870+0000] {subprocess.py:93} INFO - 
[2023-05-29T11:50:49.022+0000] {subprocess.py:93} INFO - 23/05/29 11:50:49 INFO FileOutputCommitter: Saved output of task 'attempt_202305291150134401829585508501164_0005_m_000002_9' to file:/home/cloud_user/Stock-Market-Nasdaq/data/processed_data/parquet_format_avg_med/stocks.parquet/_temporary/0/task_202305291150134401829585508501164_0005_m_000002
[2023-05-29T11:50:49.022+0000] {subprocess.py:93} INFO - 23/05/29 11:50:49 INFO SparkHadoopMapRedUtil: attempt_202305291150134401829585508501164_0005_m_000002_9: Committed. Elapsed time: 1 ms.
[2023-05-29T11:50:49.025+0000] {subprocess.py:93} INFO - 23/05/29 11:50:49 INFO Executor: Finished task 2.0 in stage 5.0 (TID 9). 4783 bytes result sent to driver
[2023-05-29T11:50:49.027+0000] {subprocess.py:93} INFO - 23/05/29 11:50:49 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 12) (4b5d28de6f1c.mylabserver.com, executor driver, partition 5, NODE_LOCAL, 7363 bytes)
[2023-05-29T11:50:49.028+0000] {subprocess.py:93} INFO - 23/05/29 11:50:49 INFO Executor: Running task 5.0 in stage 5.0 (TID 12)
[2023-05-29T11:50:49.029+0000] {subprocess.py:93} INFO - 23/05/29 11:50:49 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 9) in 13928 ms on 4b5d28de6f1c.mylabserver.com (executor driver) (4/10)
[2023-05-29T11:50:49.176+0000] {subprocess.py:93} INFO - 23/05/29 11:50:49 INFO ShuffleBlockFetcherIterator: Getting 4 (32.8 MiB) non-empty blocks including 4 (32.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-05-29T11:50:49.177+0000] {subprocess.py:93} INFO - 23/05/29 11:50:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2023-05-29T11:50:49.179+0000] {subprocess.py:93} INFO - 23/05/29 11:50:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-29T11:50:49.179+0000] {subprocess.py:93} INFO - 23/05/29 11:50:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-29T11:50:49.180+0000] {subprocess.py:93} INFO - 23/05/29 11:50:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-29T11:50:49.181+0000] {subprocess.py:93} INFO - 23/05/29 11:50:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-29T11:50:49.181+0000] {subprocess.py:93} INFO - 23/05/29 11:50:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-29T11:50:49.182+0000] {subprocess.py:93} INFO - 23/05/29 11:50:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-29T11:50:49.182+0000] {subprocess.py:93} INFO - 23/05/29 11:50:49 INFO CodecConfig: Compression: SNAPPY
[2023-05-29T11:50:49.183+0000] {subprocess.py:93} INFO - 23/05/29 11:50:49 INFO CodecConfig: Compression: SNAPPY
[2023-05-29T11:50:49.186+0000] {subprocess.py:93} INFO - 23/05/29 11:50:49 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2023-05-29T11:50:49.188+0000] {subprocess.py:93} INFO - 23/05/29 11:50:49 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2023-05-29T11:50:49.188+0000] {subprocess.py:93} INFO - {
[2023-05-29T11:50:49.188+0000] {subprocess.py:93} INFO -   "type" : "struct",
[2023-05-29T11:50:49.189+0000] {subprocess.py:93} INFO -   "fields" : [ {
[2023-05-29T11:50:49.189+0000] {subprocess.py:93} INFO -     "name" : "Date",
[2023-05-29T11:50:49.189+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:50:49.189+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:49.189+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:49.189+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:49.189+0000] {subprocess.py:93} INFO -     "name" : "Open",
[2023-05-29T11:50:49.189+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:49.190+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:49.190+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:49.190+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:49.190+0000] {subprocess.py:93} INFO -     "name" : "High",
[2023-05-29T11:50:49.190+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:49.190+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:49.190+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:49.190+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:49.191+0000] {subprocess.py:93} INFO -     "name" : "Low",
[2023-05-29T11:50:49.191+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:49.191+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:49.191+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:49.191+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:49.191+0000] {subprocess.py:93} INFO -     "name" : "Close",
[2023-05-29T11:50:49.191+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:49.191+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:49.192+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:49.192+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:49.192+0000] {subprocess.py:93} INFO -     "name" : "Adj_Close",
[2023-05-29T11:50:49.192+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:49.192+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:49.192+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:49.192+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:49.192+0000] {subprocess.py:93} INFO -     "name" : "Volume",
[2023-05-29T11:50:49.193+0000] {subprocess.py:93} INFO -     "type" : "integer",
[2023-05-29T11:50:49.193+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:49.193+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:49.193+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:49.193+0000] {subprocess.py:93} INFO -     "name" : "Symbol",
[2023-05-29T11:50:49.193+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:50:49.193+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:49.194+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:49.194+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:49.194+0000] {subprocess.py:93} INFO -     "name" : "Security_Name",
[2023-05-29T11:50:49.194+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:50:49.194+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:49.194+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:49.194+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:49.194+0000] {subprocess.py:93} INFO -     "name" : "vol_moving_avg",
[2023-05-29T11:50:49.195+0000] {subprocess.py:93} INFO -     "type" : "double",
[2023-05-29T11:50:49.195+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:49.195+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:49.195+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:49.195+0000] {subprocess.py:93} INFO -     "name" : "adj_close_rolling_med",
[2023-05-29T11:50:49.195+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:49.195+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:49.195+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:49.195+0000] {subprocess.py:93} INFO -   } ]
[2023-05-29T11:50:49.196+0000] {subprocess.py:93} INFO - }
[2023-05-29T11:50:49.196+0000] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2023-05-29T11:50:49.196+0000] {subprocess.py:93} INFO - message spark_schema {
[2023-05-29T11:50:49.196+0000] {subprocess.py:93} INFO -   optional binary Date (STRING);
[2023-05-29T11:50:49.196+0000] {subprocess.py:93} INFO -   optional float Open;
[2023-05-29T11:50:49.196+0000] {subprocess.py:93} INFO -   optional float High;
[2023-05-29T11:50:49.196+0000] {subprocess.py:93} INFO -   optional float Low;
[2023-05-29T11:50:49.196+0000] {subprocess.py:93} INFO -   optional float Close;
[2023-05-29T11:50:49.196+0000] {subprocess.py:93} INFO -   optional float Adj_Close;
[2023-05-29T11:50:49.196+0000] {subprocess.py:93} INFO -   optional int32 Volume;
[2023-05-29T11:50:49.197+0000] {subprocess.py:93} INFO -   optional binary Symbol (STRING);
[2023-05-29T11:50:49.197+0000] {subprocess.py:93} INFO -   optional binary Security_Name (STRING);
[2023-05-29T11:50:49.197+0000] {subprocess.py:93} INFO -   optional double vol_moving_avg;
[2023-05-29T11:50:49.273+0000] {subprocess.py:93} INFO -   optional float adj_close_rolling_med;
[2023-05-29T11:50:49.274+0000] {subprocess.py:93} INFO - }
[2023-05-29T11:50:49.274+0000] {subprocess.py:93} INFO - 
[2023-05-29T11:50:49.274+0000] {subprocess.py:93} INFO - 
[2023-05-29T11:50:59.414+0000] {subprocess.py:93} INFO - 23/05/29 11:50:59 INFO FileOutputCommitter: Saved output of task 'attempt_202305291150134401829585508501164_0005_m_000004_11' to file:/home/cloud_user/Stock-Market-Nasdaq/data/processed_data/parquet_format_avg_med/stocks.parquet/_temporary/0/task_202305291150134401829585508501164_0005_m_000004
[2023-05-29T11:50:59.414+0000] {subprocess.py:93} INFO - 23/05/29 11:50:59 INFO SparkHadoopMapRedUtil: attempt_202305291150134401829585508501164_0005_m_000004_11: Committed. Elapsed time: 57 ms.
[2023-05-29T11:50:59.420+0000] {subprocess.py:93} INFO - 23/05/29 11:50:59 INFO Executor: Finished task 4.0 in stage 5.0 (TID 11). 4783 bytes result sent to driver
[2023-05-29T11:50:59.423+0000] {subprocess.py:93} INFO - 23/05/29 11:50:59 INFO TaskSetManager: Starting task 6.0 in stage 5.0 (TID 13) (4b5d28de6f1c.mylabserver.com, executor driver, partition 6, NODE_LOCAL, 7363 bytes)
[2023-05-29T11:50:59.424+0000] {subprocess.py:93} INFO - 23/05/29 11:50:59 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 11) in 10722 ms on 4b5d28de6f1c.mylabserver.com (executor driver) (5/10)
[2023-05-29T11:50:59.424+0000] {subprocess.py:93} INFO - 23/05/29 11:50:59 INFO Executor: Running task 6.0 in stage 5.0 (TID 13)
[2023-05-29T11:50:59.503+0000] {subprocess.py:93} INFO - 23/05/29 11:50:59 INFO ShuffleBlockFetcherIterator: Getting 4 (32.8 MiB) non-empty blocks including 4 (32.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-05-29T11:50:59.503+0000] {subprocess.py:93} INFO - 23/05/29 11:50:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2023-05-29T11:50:59.507+0000] {subprocess.py:93} INFO - 23/05/29 11:50:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-29T11:50:59.508+0000] {subprocess.py:93} INFO - 23/05/29 11:50:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-29T11:50:59.508+0000] {subprocess.py:93} INFO - 23/05/29 11:50:59 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-29T11:50:59.509+0000] {subprocess.py:93} INFO - 23/05/29 11:50:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-29T11:50:59.509+0000] {subprocess.py:93} INFO - 23/05/29 11:50:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-29T11:50:59.510+0000] {subprocess.py:93} INFO - 23/05/29 11:50:59 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-29T11:50:59.510+0000] {subprocess.py:93} INFO - 23/05/29 11:50:59 INFO CodecConfig: Compression: SNAPPY
[2023-05-29T11:50:59.511+0000] {subprocess.py:93} INFO - 23/05/29 11:50:59 INFO CodecConfig: Compression: SNAPPY
[2023-05-29T11:50:59.514+0000] {subprocess.py:93} INFO - 23/05/29 11:50:59 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2023-05-29T11:50:59.578+0000] {subprocess.py:93} INFO - 23/05/29 11:50:59 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2023-05-29T11:50:59.578+0000] {subprocess.py:93} INFO - {
[2023-05-29T11:50:59.578+0000] {subprocess.py:93} INFO -   "type" : "struct",
[2023-05-29T11:50:59.579+0000] {subprocess.py:93} INFO -   "fields" : [ {
[2023-05-29T11:50:59.579+0000] {subprocess.py:93} INFO -     "name" : "Date",
[2023-05-29T11:50:59.579+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:50:59.579+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:59.579+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:59.579+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:59.579+0000] {subprocess.py:93} INFO -     "name" : "Open",
[2023-05-29T11:50:59.579+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:59.580+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:59.580+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:59.580+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:59.580+0000] {subprocess.py:93} INFO -     "name" : "High",
[2023-05-29T11:50:59.580+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:59.580+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:59.580+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:59.580+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:59.581+0000] {subprocess.py:93} INFO -     "name" : "Low",
[2023-05-29T11:50:59.581+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:59.581+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:59.581+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:59.581+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:59.581+0000] {subprocess.py:93} INFO -     "name" : "Close",
[2023-05-29T11:50:59.581+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:59.581+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:59.582+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:59.582+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:59.582+0000] {subprocess.py:93} INFO -     "name" : "Adj_Close",
[2023-05-29T11:50:59.582+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:59.582+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:59.582+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:59.582+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:59.582+0000] {subprocess.py:93} INFO -     "name" : "Volume",
[2023-05-29T11:50:59.583+0000] {subprocess.py:93} INFO -     "type" : "integer",
[2023-05-29T11:50:59.583+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:59.583+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:59.583+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:59.583+0000] {subprocess.py:93} INFO -     "name" : "Symbol",
[2023-05-29T11:50:59.583+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:50:59.583+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:59.583+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:59.584+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:59.584+0000] {subprocess.py:93} INFO -     "name" : "Security_Name",
[2023-05-29T11:50:59.584+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:50:59.584+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:59.584+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:59.584+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:59.584+0000] {subprocess.py:93} INFO -     "name" : "vol_moving_avg",
[2023-05-29T11:50:59.584+0000] {subprocess.py:93} INFO -     "type" : "double",
[2023-05-29T11:50:59.585+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:59.585+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:59.589+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:50:59.589+0000] {subprocess.py:93} INFO -     "name" : "adj_close_rolling_med",
[2023-05-29T11:50:59.589+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:50:59.590+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:50:59.590+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:50:59.590+0000] {subprocess.py:93} INFO -   } ]
[2023-05-29T11:50:59.590+0000] {subprocess.py:93} INFO - }
[2023-05-29T11:50:59.590+0000] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2023-05-29T11:50:59.590+0000] {subprocess.py:93} INFO - message spark_schema {
[2023-05-29T11:50:59.590+0000] {subprocess.py:93} INFO -   optional binary Date (STRING);
[2023-05-29T11:50:59.590+0000] {subprocess.py:93} INFO -   optional float Open;
[2023-05-29T11:50:59.590+0000] {subprocess.py:93} INFO -   optional float High;
[2023-05-29T11:50:59.591+0000] {subprocess.py:93} INFO -   optional float Low;
[2023-05-29T11:50:59.591+0000] {subprocess.py:93} INFO -   optional float Close;
[2023-05-29T11:50:59.591+0000] {subprocess.py:93} INFO -   optional float Adj_Close;
[2023-05-29T11:50:59.591+0000] {subprocess.py:93} INFO -   optional int32 Volume;
[2023-05-29T11:50:59.591+0000] {subprocess.py:93} INFO -   optional binary Symbol (STRING);
[2023-05-29T11:50:59.591+0000] {subprocess.py:93} INFO -   optional binary Security_Name (STRING);
[2023-05-29T11:50:59.591+0000] {subprocess.py:93} INFO -   optional double vol_moving_avg;
[2023-05-29T11:50:59.591+0000] {subprocess.py:93} INFO -   optional float adj_close_rolling_med;
[2023-05-29T11:50:59.592+0000] {subprocess.py:93} INFO - }
[2023-05-29T11:50:59.592+0000] {subprocess.py:93} INFO - 
[2023-05-29T11:50:59.592+0000] {subprocess.py:93} INFO - 
[2023-05-29T11:51:00.234+0000] {subprocess.py:93} INFO - 23/05/29 11:51:00 INFO FileOutputCommitter: Saved output of task 'attempt_202305291150134401829585508501164_0005_m_000005_12' to file:/home/cloud_user/Stock-Market-Nasdaq/data/processed_data/parquet_format_avg_med/stocks.parquet/_temporary/0/task_202305291150134401829585508501164_0005_m_000005
[2023-05-29T11:51:00.234+0000] {subprocess.py:93} INFO - 23/05/29 11:51:00 INFO SparkHadoopMapRedUtil: attempt_202305291150134401829585508501164_0005_m_000005_12: Committed. Elapsed time: 1 ms.
[2023-05-29T11:51:00.237+0000] {subprocess.py:93} INFO - 23/05/29 11:51:00 INFO Executor: Finished task 5.0 in stage 5.0 (TID 12). 4783 bytes result sent to driver
[2023-05-29T11:51:00.374+0000] {subprocess.py:93} INFO - 23/05/29 11:51:00 INFO TaskSetManager: Starting task 7.0 in stage 5.0 (TID 14) (4b5d28de6f1c.mylabserver.com, executor driver, partition 7, NODE_LOCAL, 7363 bytes)
[2023-05-29T11:51:00.374+0000] {subprocess.py:93} INFO - 23/05/29 11:51:00 INFO Executor: Running task 7.0 in stage 5.0 (TID 14)
[2023-05-29T11:51:00.380+0000] {subprocess.py:93} INFO - 23/05/29 11:51:00 INFO ShuffleBlockFetcherIterator: Getting 4 (32.8 MiB) non-empty blocks including 4 (32.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-05-29T11:51:00.381+0000] {subprocess.py:93} INFO - 23/05/29 11:51:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2023-05-29T11:51:00.383+0000] {subprocess.py:93} INFO - 23/05/29 11:51:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-29T11:51:00.383+0000] {subprocess.py:93} INFO - 23/05/29 11:51:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-29T11:51:00.383+0000] {subprocess.py:93} INFO - 23/05/29 11:51:00 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-29T11:51:00.383+0000] {subprocess.py:93} INFO - 23/05/29 11:51:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-29T11:51:00.383+0000] {subprocess.py:93} INFO - 23/05/29 11:51:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-29T11:51:00.384+0000] {subprocess.py:93} INFO - 23/05/29 11:51:00 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-29T11:51:00.384+0000] {subprocess.py:93} INFO - 23/05/29 11:51:00 INFO CodecConfig: Compression: SNAPPY
[2023-05-29T11:51:00.384+0000] {subprocess.py:93} INFO - 23/05/29 11:51:00 INFO CodecConfig: Compression: SNAPPY
[2023-05-29T11:51:00.387+0000] {subprocess.py:93} INFO - 23/05/29 11:51:00 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2023-05-29T11:51:00.391+0000] {subprocess.py:93} INFO - 23/05/29 11:51:00 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2023-05-29T11:51:00.391+0000] {subprocess.py:93} INFO - {
[2023-05-29T11:51:00.391+0000] {subprocess.py:93} INFO -   "type" : "struct",
[2023-05-29T11:51:00.392+0000] {subprocess.py:93} INFO -   "fields" : [ {
[2023-05-29T11:51:00.392+0000] {subprocess.py:93} INFO -     "name" : "Date",
[2023-05-29T11:51:00.392+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:51:00.392+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:00.392+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:00.392+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:00.392+0000] {subprocess.py:93} INFO -     "name" : "Open",
[2023-05-29T11:51:00.392+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:51:00.392+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:00.393+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:00.393+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:00.393+0000] {subprocess.py:93} INFO -     "name" : "High",
[2023-05-29T11:51:00.393+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:51:00.393+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:00.393+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:00.393+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:00.394+0000] {subprocess.py:93} INFO -     "name" : "Low",
[2023-05-29T11:51:00.394+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:51:00.394+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:00.394+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:00.394+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:00.394+0000] {subprocess.py:93} INFO -     "name" : "Close",
[2023-05-29T11:51:00.394+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:51:00.394+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:00.395+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:00.395+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:00.395+0000] {subprocess.py:93} INFO -     "name" : "Adj_Close",
[2023-05-29T11:51:00.395+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:51:00.395+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:00.395+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:00.395+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:00.395+0000] {subprocess.py:93} INFO -     "name" : "Volume",
[2023-05-29T11:51:00.396+0000] {subprocess.py:93} INFO -     "type" : "integer",
[2023-05-29T11:51:00.396+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:00.396+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:00.396+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:00.396+0000] {subprocess.py:93} INFO -     "name" : "Symbol",
[2023-05-29T11:51:00.396+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:51:00.396+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:00.396+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:00.397+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:00.397+0000] {subprocess.py:93} INFO -     "name" : "Security_Name",
[2023-05-29T11:51:00.454+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:51:00.454+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:00.454+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:00.454+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:00.454+0000] {subprocess.py:93} INFO -     "name" : "vol_moving_avg",
[2023-05-29T11:51:00.455+0000] {subprocess.py:93} INFO -     "type" : "double",
[2023-05-29T11:51:00.455+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:00.455+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:00.455+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:00.455+0000] {subprocess.py:93} INFO -     "name" : "adj_close_rolling_med",
[2023-05-29T11:51:00.455+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:51:00.455+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:00.455+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:00.456+0000] {subprocess.py:93} INFO -   } ]
[2023-05-29T11:51:00.456+0000] {subprocess.py:93} INFO - }
[2023-05-29T11:51:00.456+0000] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2023-05-29T11:51:00.456+0000] {subprocess.py:93} INFO - message spark_schema {
[2023-05-29T11:51:00.456+0000] {subprocess.py:93} INFO -   optional binary Date (STRING);
[2023-05-29T11:51:00.456+0000] {subprocess.py:93} INFO -   optional float Open;
[2023-05-29T11:51:00.456+0000] {subprocess.py:93} INFO -   optional float High;
[2023-05-29T11:51:00.456+0000] {subprocess.py:93} INFO -   optional float Low;
[2023-05-29T11:51:00.457+0000] {subprocess.py:93} INFO -   optional float Close;
[2023-05-29T11:51:00.457+0000] {subprocess.py:93} INFO -   optional float Adj_Close;
[2023-05-29T11:51:00.461+0000] {subprocess.py:93} INFO -   optional int32 Volume;
[2023-05-29T11:51:00.461+0000] {subprocess.py:93} INFO -   optional binary Symbol (STRING);
[2023-05-29T11:51:00.461+0000] {subprocess.py:93} INFO -   optional binary Security_Name (STRING);
[2023-05-29T11:51:00.461+0000] {subprocess.py:93} INFO -   optional double vol_moving_avg;
[2023-05-29T11:51:00.462+0000] {subprocess.py:93} INFO -   optional float adj_close_rolling_med;
[2023-05-29T11:51:00.462+0000] {subprocess.py:93} INFO - }
[2023-05-29T11:51:00.462+0000] {subprocess.py:93} INFO - 
[2023-05-29T11:51:00.462+0000] {subprocess.py:93} INFO - 
[2023-05-29T11:51:00.462+0000] {subprocess.py:93} INFO - 23/05/29 11:51:00 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 12) in 11212 ms on 4b5d28de6f1c.mylabserver.com (executor driver) (6/10)
[2023-05-29T11:51:08.466+0000] {subprocess.py:93} INFO - 23/05/29 11:51:08 INFO FileOutputCommitter: Saved output of task 'attempt_202305291150134401829585508501164_0005_m_000007_14' to file:/home/cloud_user/Stock-Market-Nasdaq/data/processed_data/parquet_format_avg_med/stocks.parquet/_temporary/0/task_202305291150134401829585508501164_0005_m_000007
[2023-05-29T11:51:08.466+0000] {subprocess.py:93} INFO - 23/05/29 11:51:08 INFO SparkHadoopMapRedUtil: attempt_202305291150134401829585508501164_0005_m_000007_14: Committed. Elapsed time: 1 ms.
[2023-05-29T11:51:08.473+0000] {subprocess.py:93} INFO - 23/05/29 11:51:08 INFO Executor: Finished task 7.0 in stage 5.0 (TID 14). 4783 bytes result sent to driver
[2023-05-29T11:51:08.477+0000] {subprocess.py:93} INFO - 23/05/29 11:51:08 INFO TaskSetManager: Starting task 8.0 in stage 5.0 (TID 15) (4b5d28de6f1c.mylabserver.com, executor driver, partition 8, NODE_LOCAL, 7363 bytes)
[2023-05-29T11:51:08.478+0000] {subprocess.py:93} INFO - 23/05/29 11:51:08 INFO TaskSetManager: Finished task 7.0 in stage 5.0 (TID 14) in 8239 ms on 4b5d28de6f1c.mylabserver.com (executor driver) (7/10)
[2023-05-29T11:51:08.629+0000] {subprocess.py:93} INFO - 23/05/29 11:51:08 INFO Executor: Running task 8.0 in stage 5.0 (TID 15)
[2023-05-29T11:51:08.630+0000] {subprocess.py:93} INFO - 23/05/29 11:51:08 INFO ShuffleBlockFetcherIterator: Getting 4 (32.8 MiB) non-empty blocks including 4 (32.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-05-29T11:51:08.630+0000] {subprocess.py:93} INFO - 23/05/29 11:51:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 56 ms
[2023-05-29T11:51:08.630+0000] {subprocess.py:93} INFO - 23/05/29 11:51:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-29T11:51:08.630+0000] {subprocess.py:93} INFO - 23/05/29 11:51:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-29T11:51:08.630+0000] {subprocess.py:93} INFO - 23/05/29 11:51:08 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-29T11:51:08.630+0000] {subprocess.py:93} INFO - 23/05/29 11:51:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-29T11:51:08.630+0000] {subprocess.py:93} INFO - 23/05/29 11:51:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-29T11:51:08.630+0000] {subprocess.py:93} INFO - 23/05/29 11:51:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-29T11:51:08.631+0000] {subprocess.py:93} INFO - 23/05/29 11:51:08 INFO CodecConfig: Compression: SNAPPY
[2023-05-29T11:51:08.631+0000] {subprocess.py:93} INFO - 23/05/29 11:51:08 INFO CodecConfig: Compression: SNAPPY
[2023-05-29T11:51:08.631+0000] {subprocess.py:93} INFO - 23/05/29 11:51:08 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2023-05-29T11:51:08.631+0000] {subprocess.py:93} INFO - 23/05/29 11:51:08 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2023-05-29T11:51:08.631+0000] {subprocess.py:93} INFO - {
[2023-05-29T11:51:08.631+0000] {subprocess.py:93} INFO -   "type" : "struct",
[2023-05-29T11:51:08.631+0000] {subprocess.py:93} INFO -   "fields" : [ {
[2023-05-29T11:51:08.631+0000] {subprocess.py:93} INFO -     "name" : "Date",
[2023-05-29T11:51:08.631+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:51:08.632+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:08.632+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:08.632+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:08.632+0000] {subprocess.py:93} INFO -     "name" : "Open",
[2023-05-29T11:51:08.632+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:51:08.632+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:08.632+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:08.632+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:08.632+0000] {subprocess.py:93} INFO -     "name" : "High",
[2023-05-29T11:51:08.632+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:51:08.633+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:08.633+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:08.633+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:08.633+0000] {subprocess.py:93} INFO -     "name" : "Low",
[2023-05-29T11:51:08.633+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:51:08.633+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:08.633+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:08.633+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:08.633+0000] {subprocess.py:93} INFO -     "name" : "Close",
[2023-05-29T11:51:08.634+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:51:08.634+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:08.634+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:08.634+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:08.634+0000] {subprocess.py:93} INFO -     "name" : "Adj_Close",
[2023-05-29T11:51:08.634+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:51:08.634+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:08.634+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:08.634+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:08.634+0000] {subprocess.py:93} INFO -     "name" : "Volume",
[2023-05-29T11:51:08.635+0000] {subprocess.py:93} INFO -     "type" : "integer",
[2023-05-29T11:51:08.635+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:08.635+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:08.635+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:08.635+0000] {subprocess.py:93} INFO -     "name" : "Symbol",
[2023-05-29T11:51:08.635+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:51:08.635+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:08.635+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:08.635+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:08.636+0000] {subprocess.py:93} INFO -     "name" : "Security_Name",
[2023-05-29T11:51:08.636+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:51:08.636+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:08.636+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:08.636+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:08.636+0000] {subprocess.py:93} INFO -     "name" : "vol_moving_avg",
[2023-05-29T11:51:08.636+0000] {subprocess.py:93} INFO -     "type" : "double",
[2023-05-29T11:51:08.636+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:08.636+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:08.637+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:08.637+0000] {subprocess.py:93} INFO -     "name" : "adj_close_rolling_med",
[2023-05-29T11:51:08.694+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:51:08.694+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:08.694+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:08.695+0000] {subprocess.py:93} INFO -   } ]
[2023-05-29T11:51:08.695+0000] {subprocess.py:93} INFO - }
[2023-05-29T11:51:08.695+0000] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2023-05-29T11:51:08.695+0000] {subprocess.py:93} INFO - message spark_schema {
[2023-05-29T11:51:08.695+0000] {subprocess.py:93} INFO -   optional binary Date (STRING);
[2023-05-29T11:51:08.695+0000] {subprocess.py:93} INFO -   optional float Open;
[2023-05-29T11:51:08.695+0000] {subprocess.py:93} INFO -   optional float High;
[2023-05-29T11:51:08.695+0000] {subprocess.py:93} INFO -   optional float Low;
[2023-05-29T11:51:08.695+0000] {subprocess.py:93} INFO -   optional float Close;
[2023-05-29T11:51:08.696+0000] {subprocess.py:93} INFO -   optional float Adj_Close;
[2023-05-29T11:51:08.696+0000] {subprocess.py:93} INFO -   optional int32 Volume;
[2023-05-29T11:51:08.696+0000] {subprocess.py:93} INFO -   optional binary Symbol (STRING);
[2023-05-29T11:51:08.696+0000] {subprocess.py:93} INFO -   optional binary Security_Name (STRING);
[2023-05-29T11:51:08.696+0000] {subprocess.py:93} INFO -   optional double vol_moving_avg;
[2023-05-29T11:51:08.696+0000] {subprocess.py:93} INFO -   optional float adj_close_rolling_med;
[2023-05-29T11:51:08.696+0000] {subprocess.py:93} INFO - }
[2023-05-29T11:51:08.696+0000] {subprocess.py:93} INFO - 
[2023-05-29T11:51:08.696+0000] {subprocess.py:93} INFO - 
[2023-05-29T11:51:08.934+0000] {subprocess.py:93} INFO - 23/05/29 11:51:08 INFO FileOutputCommitter: Saved output of task 'attempt_202305291150134401829585508501164_0005_m_000006_13' to file:/home/cloud_user/Stock-Market-Nasdaq/data/processed_data/parquet_format_avg_med/stocks.parquet/_temporary/0/task_202305291150134401829585508501164_0005_m_000006
[2023-05-29T11:51:08.935+0000] {subprocess.py:93} INFO - 23/05/29 11:51:08 INFO SparkHadoopMapRedUtil: attempt_202305291150134401829585508501164_0005_m_000006_13: Committed. Elapsed time: 57 ms.
[2023-05-29T11:51:08.937+0000] {subprocess.py:93} INFO - 23/05/29 11:51:08 INFO Executor: Finished task 6.0 in stage 5.0 (TID 13). 4783 bytes result sent to driver
[2023-05-29T11:51:08.938+0000] {subprocess.py:93} INFO - 23/05/29 11:51:08 INFO TaskSetManager: Starting task 9.0 in stage 5.0 (TID 16) (4b5d28de6f1c.mylabserver.com, executor driver, partition 9, NODE_LOCAL, 7363 bytes)
[2023-05-29T11:51:08.945+0000] {subprocess.py:93} INFO - 23/05/29 11:51:08 INFO Executor: Running task 9.0 in stage 5.0 (TID 16)
[2023-05-29T11:51:08.946+0000] {subprocess.py:93} INFO - 23/05/29 11:51:08 INFO TaskSetManager: Finished task 6.0 in stage 5.0 (TID 13) in 9518 ms on 4b5d28de6f1c.mylabserver.com (executor driver) (8/10)
[2023-05-29T11:51:09.015+0000] {subprocess.py:93} INFO - 23/05/29 11:51:09 INFO ShuffleBlockFetcherIterator: Getting 4 (32.8 MiB) non-empty blocks including 4 (32.8 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2023-05-29T11:51:09.016+0000] {subprocess.py:93} INFO - 23/05/29 11:51:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2023-05-29T11:51:09.018+0000] {subprocess.py:93} INFO - 23/05/29 11:51:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-29T11:51:09.018+0000] {subprocess.py:93} INFO - 23/05/29 11:51:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-29T11:51:09.019+0000] {subprocess.py:93} INFO - 23/05/29 11:51:09 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-29T11:51:09.019+0000] {subprocess.py:93} INFO - 23/05/29 11:51:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2023-05-29T11:51:09.019+0000] {subprocess.py:93} INFO - 23/05/29 11:51:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2023-05-29T11:51:09.020+0000] {subprocess.py:93} INFO - 23/05/29 11:51:09 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2023-05-29T11:51:09.020+0000] {subprocess.py:93} INFO - 23/05/29 11:51:09 INFO CodecConfig: Compression: SNAPPY
[2023-05-29T11:51:09.021+0000] {subprocess.py:93} INFO - 23/05/29 11:51:09 INFO CodecConfig: Compression: SNAPPY
[2023-05-29T11:51:09.023+0000] {subprocess.py:93} INFO - 23/05/29 11:51:09 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2023-05-29T11:51:09.025+0000] {subprocess.py:93} INFO - 23/05/29 11:51:09 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2023-05-29T11:51:09.025+0000] {subprocess.py:93} INFO - {
[2023-05-29T11:51:09.025+0000] {subprocess.py:93} INFO -   "type" : "struct",
[2023-05-29T11:51:09.025+0000] {subprocess.py:93} INFO -   "fields" : [ {
[2023-05-29T11:51:09.025+0000] {subprocess.py:93} INFO -     "name" : "Date",
[2023-05-29T11:51:09.026+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:51:09.026+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:09.026+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:09.026+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:09.026+0000] {subprocess.py:93} INFO -     "name" : "Open",
[2023-05-29T11:51:09.026+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:51:09.026+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:09.026+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:09.026+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:09.027+0000] {subprocess.py:93} INFO -     "name" : "High",
[2023-05-29T11:51:09.027+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:51:09.027+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:09.027+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:09.027+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:09.027+0000] {subprocess.py:93} INFO -     "name" : "Low",
[2023-05-29T11:51:09.027+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:51:09.027+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:09.027+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:09.028+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:09.028+0000] {subprocess.py:93} INFO -     "name" : "Close",
[2023-05-29T11:51:09.028+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:51:09.028+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:09.028+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:09.028+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:09.028+0000] {subprocess.py:93} INFO -     "name" : "Adj_Close",
[2023-05-29T11:51:09.028+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:51:09.028+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:09.028+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:09.029+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:09.029+0000] {subprocess.py:93} INFO -     "name" : "Volume",
[2023-05-29T11:51:09.029+0000] {subprocess.py:93} INFO -     "type" : "integer",
[2023-05-29T11:51:09.029+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:09.029+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:09.029+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:09.029+0000] {subprocess.py:93} INFO -     "name" : "Symbol",
[2023-05-29T11:51:09.029+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:51:09.030+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:09.030+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:09.030+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:09.030+0000] {subprocess.py:93} INFO -     "name" : "Security_Name",
[2023-05-29T11:51:09.030+0000] {subprocess.py:93} INFO -     "type" : "string",
[2023-05-29T11:51:09.030+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:09.030+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:09.030+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:09.030+0000] {subprocess.py:93} INFO -     "name" : "vol_moving_avg",
[2023-05-29T11:51:09.031+0000] {subprocess.py:93} INFO -     "type" : "double",
[2023-05-29T11:51:09.031+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:09.031+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:09.031+0000] {subprocess.py:93} INFO -   }, {
[2023-05-29T11:51:09.031+0000] {subprocess.py:93} INFO -     "name" : "adj_close_rolling_med",
[2023-05-29T11:51:09.031+0000] {subprocess.py:93} INFO -     "type" : "float",
[2023-05-29T11:51:09.031+0000] {subprocess.py:93} INFO -     "nullable" : true,
[2023-05-29T11:51:09.031+0000] {subprocess.py:93} INFO -     "metadata" : { }
[2023-05-29T11:51:09.031+0000] {subprocess.py:93} INFO -   } ]
[2023-05-29T11:51:09.031+0000] {subprocess.py:93} INFO - }
[2023-05-29T11:51:09.032+0000] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2023-05-29T11:51:09.032+0000] {subprocess.py:93} INFO - message spark_schema {
[2023-05-29T11:51:09.032+0000] {subprocess.py:93} INFO -   optional binary Date (STRING);
[2023-05-29T11:51:09.032+0000] {subprocess.py:93} INFO -   optional float Open;
[2023-05-29T11:51:09.032+0000] {subprocess.py:93} INFO -   optional float High;
[2023-05-29T11:51:09.032+0000] {subprocess.py:93} INFO -   optional float Low;
[2023-05-29T11:51:09.032+0000] {subprocess.py:93} INFO -   optional float Close;
[2023-05-29T11:51:09.032+0000] {subprocess.py:93} INFO -   optional float Adj_Close;
[2023-05-29T11:51:09.032+0000] {subprocess.py:93} INFO -   optional int32 Volume;
[2023-05-29T11:51:09.033+0000] {subprocess.py:93} INFO -   optional binary Symbol (STRING);
[2023-05-29T11:51:09.033+0000] {subprocess.py:93} INFO -   optional binary Security_Name (STRING);
[2023-05-29T11:51:09.034+0000] {subprocess.py:93} INFO -   optional double vol_moving_avg;
[2023-05-29T11:51:09.034+0000] {subprocess.py:93} INFO -   optional float adj_close_rolling_med;
[2023-05-29T11:51:09.034+0000] {subprocess.py:93} INFO - }
[2023-05-29T11:51:09.034+0000] {subprocess.py:93} INFO - 
[2023-05-29T11:51:09.034+0000] {subprocess.py:93} INFO - 
[2023-05-29T11:51:17.503+0000] {subprocess.py:93} INFO - 23/05/29 11:51:17 INFO FileOutputCommitter: Saved output of task 'attempt_202305291150134401829585508501164_0005_m_000009_16' to file:/home/cloud_user/Stock-Market-Nasdaq/data/processed_data/parquet_format_avg_med/stocks.parquet/_temporary/0/task_202305291150134401829585508501164_0005_m_000009
[2023-05-29T11:51:17.503+0000] {subprocess.py:93} INFO - 23/05/29 11:51:17 INFO SparkHadoopMapRedUtil: attempt_202305291150134401829585508501164_0005_m_000009_16: Committed. Elapsed time: 1 ms.
[2023-05-29T11:51:17.504+0000] {subprocess.py:93} INFO - 23/05/29 11:51:17 INFO Executor: Finished task 9.0 in stage 5.0 (TID 16). 4783 bytes result sent to driver
[2023-05-29T11:51:17.506+0000] {subprocess.py:93} INFO - 23/05/29 11:51:17 INFO TaskSetManager: Finished task 9.0 in stage 5.0 (TID 16) in 8568 ms on 4b5d28de6f1c.mylabserver.com (executor driver) (9/10)
[2023-05-29T11:51:17.516+0000] {subprocess.py:93} INFO - 23/05/29 11:51:17 INFO FileOutputCommitter: Saved output of task 'attempt_202305291150134401829585508501164_0005_m_000008_15' to file:/home/cloud_user/Stock-Market-Nasdaq/data/processed_data/parquet_format_avg_med/stocks.parquet/_temporary/0/task_202305291150134401829585508501164_0005_m_000008
[2023-05-29T11:51:17.516+0000] {subprocess.py:93} INFO - 23/05/29 11:51:17 INFO SparkHadoopMapRedUtil: attempt_202305291150134401829585508501164_0005_m_000008_15: Committed. Elapsed time: 1 ms.
[2023-05-29T11:51:17.575+0000] {subprocess.py:93} INFO - 23/05/29 11:51:17 INFO Executor: Finished task 8.0 in stage 5.0 (TID 15). 4783 bytes result sent to driver
[2023-05-29T11:51:17.577+0000] {subprocess.py:93} INFO - 23/05/29 11:51:17 INFO TaskSetManager: Finished task 8.0 in stage 5.0 (TID 15) in 9102 ms on 4b5d28de6f1c.mylabserver.com (executor driver) (10/10)
[2023-05-29T11:51:17.577+0000] {subprocess.py:93} INFO - 23/05/29 11:51:17 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2023-05-29T11:51:17.581+0000] {subprocess.py:93} INFO - 23/05/29 11:51:17 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 64.477 s
[2023-05-29T11:51:17.581+0000] {subprocess.py:93} INFO - 23/05/29 11:51:17 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2023-05-29T11:51:17.581+0000] {subprocess.py:93} INFO - 23/05/29 11:51:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2023-05-29T11:51:17.581+0000] {subprocess.py:93} INFO - 23/05/29 11:51:17 INFO DAGScheduler: Job 2 finished: parquet at NativeMethodAccessorImpl.java:0, took 64.550631 s
[2023-05-29T11:51:17.583+0000] {subprocess.py:93} INFO - 23/05/29 11:51:17 INFO FileFormatWriter: Start to commit write Job 12a1c376-248f-48c9-8f75-bbd113a1eb12.
[2023-05-29T11:51:17.668+0000] {subprocess.py:93} INFO - 23/05/29 11:51:17 INFO FileFormatWriter: Write Job 12a1c376-248f-48c9-8f75-bbd113a1eb12 committed. Elapsed time: 84 ms.
[2023-05-29T11:51:17.737+0000] {subprocess.py:93} INFO - 23/05/29 11:51:17 INFO FileFormatWriter: Finished processing stats for write job 12a1c376-248f-48c9-8f75-bbd113a1eb12.
[2023-05-29T11:51:18.320+0000] {subprocess.py:93} INFO - 23/05/29 11:51:18 INFO SparkContext: Invoking stop() from shutdown hook
[2023-05-29T11:51:18.321+0000] {subprocess.py:93} INFO - 23/05/29 11:51:18 INFO SparkContext: SparkContext is stopping with exitCode 0.
[2023-05-29T11:51:18.387+0000] {subprocess.py:93} INFO - 23/05/29 11:51:18 INFO SparkUI: Stopped Spark web UI at http://4b5d28de6f1c.mylabserver.com:4040
[2023-05-29T11:51:18.461+0000] {subprocess.py:93} INFO - 23/05/29 11:51:18 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2023-05-29T11:51:18.876+0000] {subprocess.py:93} INFO - 23/05/29 11:51:18 INFO MemoryStore: MemoryStore cleared
[2023-05-29T11:51:18.876+0000] {subprocess.py:93} INFO - 23/05/29 11:51:18 INFO BlockManager: BlockManager stopped
[2023-05-29T11:51:18.942+0000] {subprocess.py:93} INFO - 23/05/29 11:51:18 INFO BlockManagerMaster: BlockManagerMaster stopped
[2023-05-29T11:51:18.944+0000] {subprocess.py:93} INFO - 23/05/29 11:51:18 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2023-05-29T11:51:18.957+0000] {subprocess.py:93} INFO - 23/05/29 11:51:18 INFO SparkContext: Successfully stopped SparkContext
[2023-05-29T11:51:18.957+0000] {subprocess.py:93} INFO - 23/05/29 11:51:18 INFO ShutdownHookManager: Shutdown hook called
[2023-05-29T11:51:18.958+0000] {subprocess.py:93} INFO - 23/05/29 11:51:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-e4f389ab-8bc2-47af-b4ee-4ce224eb7507
[2023-05-29T11:51:19.018+0000] {subprocess.py:93} INFO - 23/05/29 11:51:19 INFO ShutdownHookManager: Deleting directory /tmp/spark-e4f389ab-8bc2-47af-b4ee-4ce224eb7507/pyspark-cc5199d0-0319-4399-8825-7697dc4c71f8
[2023-05-29T11:51:19.022+0000] {subprocess.py:93} INFO - 23/05/29 11:51:19 INFO ShutdownHookManager: Deleting directory /tmp/spark-0d495dd0-2ef4-462a-a750-27789eedab0f
[2023-05-29T11:51:19.277+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2023-05-29T11:51:19.298+0000] {taskinstance.py:1345} INFO - Marking task as SUCCESS. dag_id=stock_market_dag, task_id=feature_engineering_stocks, execution_date=20230529T092654, start_date=20230529T103109, end_date=20230529T115119
[2023-05-29T11:51:19.378+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-05-29T11:51:19.391+0000] {taskinstance.py:2651} INFO - 1 downstream tasks scheduled from follow-on schedule check
